import streamlit as st
import json
import networkx as nx
from pathlib import Path
import streamlit.components.v1 as components
import sys
from datetime import datetime
import altair as alt
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT_DIR))

from src.web import utils

st.set_page_config(page_title="Knowledge Graph - Market Lens", page_icon="ğŸ•¸ï¸", layout="wide")

# --- æ•°æ®åŠ è½½ ---
data_root = Path(__file__).resolve().parent.parent / "data"
kg_file = data_root / "knowledge_graph.json"
kg_vis_file = data_root / "kg_visual.json"
kg_timeline_file = data_root / "kg_visual_timeline.json"
with st.spinner("Loading graph data..."):
    entities = utils.load_entities()
    events = utils.load_events()

    kg_data = {}
    if kg_file.exists():
        try:
            kg_data = json.loads(kg_file.read_text(encoding="utf-8"))
        except Exception as e:
            st.warning(f"çŸ¥è¯†å›¾è°±æ–‡ä»¶è§£æå¤±è´¥ï¼Œå·²å›é€€ï¼š{e}")
            kg_data = {}

    kg_vis_data = {}
    if kg_vis_file.exists():
        try:
            kg_vis_data = json.loads(kg_vis_file.read_text(encoding="utf-8"))
        except Exception as e:
            st.warning(f"å¿«ç…§ kg_visual.json è§£æå¤±è´¥ï¼Œå·²å›é€€åŸå§‹å›¾è°±ï¼š{e}")
            kg_vis_data = {}
    else:
        st.info("æœªæ‰¾åˆ° kg_visual.jsonï¼Œå°†ä½¿ç”¨åŸå§‹çŸ¥è¯†å›¾è°±æ•°æ®ã€‚")

    kg_timeline_data = []
    if kg_timeline_file.exists():
        try:
            kg_timeline_data = json.loads(kg_timeline_file.read_text(encoding="utf-8"))
        except Exception as e:
            st.warning(f"æ—¶é—´çº¿å¿«ç…§ kg_visual_timeline.json è§£æå¤±è´¥ï¼Œå·²å›é€€åŸå§‹äº‹ä»¶ï¼š{e}")
            kg_timeline_data = []
    else:
        st.info("æœªæ‰¾åˆ° kg_visual_timeline.jsonï¼Œå°†ä½¿ç”¨åŸå§‹äº‹ä»¶æ•°æ®ã€‚")

# --- ä¾§è¾¹æ æ§åˆ¶ ---
with st.sidebar:
    mode = st.radio("æ•°æ®æº", ["äº‹ä»¶-å®ä½“æ˜ å°„ (EA)", "å‹ç¼©å›¾è°± (KG)"], index=0)
    all_entities = list(entities.keys()) if mode == "äº‹ä»¶-å®ä½“æ˜ å°„ (EA)" else list((kg_data.get("entities") or {}).keys())
    placeholder_label = "(All / Top Nodes - EA)" if mode == "äº‹ä»¶-å®ä½“æ˜ å°„ (EA)" else "(All / Top Nodes - KG)"
    search_query = st.selectbox(
        "Focus on Entity", 
        options=[placeholder_label] + sorted(all_entities),
        index=0,
        help="Select an entity to view its specific connections."
    )
    hop_depth = st.slider("Hop Depth (èšç„¦æ¨¡å¼)", 1, 4, 1, help="ä»é€‰å®šå®ä½“å‡ºå‘ï¼Œæœ€å¤šæ‹“å±•çš„è¾¹æ•°ï¼ˆå®ä½“-äº‹ä»¶-å®ä½“-...ï¼‰ã€‚")
    
    # 2. æ˜¾ç¤ºè®¾ç½®
    max_nodes = st.slider("Max Nodes", 10, 3000, 500, help="Limit total nodes for better performance")
    physics_enabled = st.checkbox("Enable Physics", value=True)
    auto_timeline = st.checkbox("æ˜¾ç¤ºèšç„¦å®ä½“æ—¶é—´çº¿", value=True, help="åœ¨ä¸‹æ–¹æ—¶é—´çº¿è§†å›¾ä¸­è‡ªåŠ¨ä½¿ç”¨å½“å‰èšç„¦å®ä½“ï¼ˆKG/EA å‡å¯ï¼‰")
    
    # æ—¶é—´çº¿å‚æ•°
    entity_opts = sorted(list(entities.keys()))
    default_tl = "(è¯·é€‰æ‹©)"
    if auto_timeline and search_query not in ["(All / Top Nodes - EA)", "(All / Top Nodes - KG)", "(All / Top Nodes)"]:
        default_tl = search_query
    # æ—¶é—´çº¿å®ä½“ç›´æ¥å¤ç”¨å½“å‰èšç„¦å®ä½“ï¼ˆé All/Topï¼‰ï¼Œå¦åˆ™ä¸ºæœªé€‰æ‹©
    timeline_entity = search_query if search_query not in [placeholder_label, "(All / Top Nodes)"] else "(è¯·é€‰æ‹©)"
    limit_events = st.slider("æœ€å¤šæ˜¾ç¤ºäº‹ä»¶æ•°", 10, 500, 200, 10)
    
    st.divider()
    if mode == "äº‹ä»¶-å®ä½“æ˜ å°„ (EA)":
        st.caption(f"Total Entities: {len(entities)}")
        st.caption(f"Total Events: {len(events)}")
    else:
        if kg_vis_data:
            st.caption(f"KG (vis) Nodes: {len(kg_vis_data.get('nodes') or [])}")
            st.caption(f"KG (vis) Edges: {len(kg_vis_data.get('edges') or [])}")
        else:
            st.caption(f"KG Entities: {len(kg_data.get('entities') or {})}")
            st.caption(f"KG Events: {len(kg_data.get('events') or {})}")

if mode == "äº‹ä»¶-å®ä½“æ˜ å°„ (EA)":
    if not entities or not events:
        st.warning("Knowledge Graph is empty. Run the pipeline to populate data.")
        st.stop()
else:
    # KG æ¨¡å¼ä¼˜å…ˆç”¨å¯è§†åŒ–å¿«ç…§
    if kg_vis_data:
        pass
    elif not kg_data or not kg_data.get("entities") or not kg_data.get("events"):
        st.warning("Knowledge Graph (KG) is empty.")
        st.stop()

edge_list = []
event_ids = set()
if mode == "äº‹ä»¶-å®ä½“æ˜ å°„ (EA)":
    event_ids = {f"EVT:{k}" for k in events.keys()}
    for evt_abstract, evt_data in events.items():
        evt_id = f"EVT:{evt_abstract}"  #ä»¥æ­¤åŒºåˆ†
        evt_summary = evt_data.get('event_summary', evt_abstract)
        for ent in evt_data.get('entities', []):
            if ent in entities:
                edge_list.append((evt_id, ent, {"title": evt_summary}))
else:
    if kg_vis_data:
        vis_nodes = kg_vis_data.get("nodes", [])
        vis_edges = kg_vis_data.get("edges", [])
        for n in vis_nodes:
            if n.get("type") == "event":
                event_ids.add(n.get("id"))
        for e in vis_edges:
            u, v = e.get("from"), e.get("to")
            edge_list.append((u, v, {"title": e.get("title", "")}))
    else:
        kg_entities = kg_data.get("entities", {})
        kg_events = kg_data.get("events", {})
        kg_edges = kg_data.get("edges", [])
        event_ids = set(kg_events.keys())
        for e in kg_edges:
            u = e.get("from")
            v = e.get("to")
            if not u or not v:
                continue
            title = ""
            evt_key = v[4:] if isinstance(v, str) and v.startswith("EVT:") else v
            if evt_key in kg_events:
                title = kg_events[evt_key].get("event_summary", "") or kg_events[evt_key].get("abstract", "")
            edge_list.append((u, v, {"title": title}))

# --- è¿‡æ»¤é€»è¾‘ ---
target_nodes = set()
from collections import defaultdict, deque
adj = defaultdict(set)
for u, v, _ in edge_list:
    adj[u].add(v)
    adj[v].add(u)

# èŠ‚ç‚¹ç±»å‹åˆ¤æ–­
def is_event_node(node: str) -> bool:
    if isinstance(node, str) and node.startswith("EVT:"):
        return True
    return node in event_ids

if search_query != "(All / Top Nodes)" and search_query != "(All / Top Nodes - EA)" and search_query != "(All / Top Nodes - KG)":
    # 1. èšç„¦æ¨¡å¼ï¼šä»é€‰å®šå®ä½“å‡ºå‘ï¼ŒæŒ‰ hop_depth åš BFSï¼ˆå®ä½“-äº‹ä»¶äº¤æ›¿ï¼‰
    target_nodes.add(search_query)
    frontier = {search_query}
    for _ in range(hop_depth):
        next_frontier = set()
        for node in frontier:
            next_frontier |= adj.get(node, set())
        next_frontier -= target_nodes
        target_nodes |= next_frontier
        frontier = next_frontier
else:
    # 2. å…¨å±€æ¨¡å¼ï¼šæŒ‰åº¦æ•°ï¼ˆè¿æ¥æ•°ï¼‰å– Top N å®ä½“ + ç›¸å…³äº‹ä»¶
    # ç®€å•èµ·è§ï¼Œå…ˆç»Ÿè®¡å®ä½“å‡ºç°é¢‘ç‡
    # ä¹Ÿå¯ä»¥ç›´æ¥ç”¨ edge_list æ„å»ºä¸´æ—¶å›¾è®¡ç®—åº¦
    temp_G = nx.Graph()
    temp_G.add_edges_from([(u, v) for u, v, _ in edge_list])
    
    # è®¡ç®—åº¦
    degrees = dict(temp_G.degree())
    # æ’åº
    top_nodes = sorted(degrees, key=degrees.get, reverse=True)[:max_nodes]
    target_nodes = set(top_nodes)

# --- æ„å»ºæœ€ç»ˆå¯è§†åŒ–å›¾ ---
visual_G = nx.Graph()

count = 0
for u, v, attr in edge_list:
    if u in target_nodes and v in target_nodes:
        # æ·»åŠ èŠ‚ç‚¹ï¼ˆå¦‚æœæœªæ·»åŠ ï¼‰
        if u not in visual_G:
            # åˆ¤æ–­ç±»å‹
            if is_event_node(u):
                label = u[4:20] + "..." if isinstance(u, str) and u.startswith("EVT:") else str(u)[:20] + "..."
                visual_G.add_node(u, label=label, title=str(u)[4:] if isinstance(u, str) and u.startswith("EVT:") else str(u), group='Event', color='#ff7f0e', size=15)
            else:
                visual_G.add_node(u, label=str(u), group='Entity', color='#1f77b4', size=25)
        
        if v not in visual_G:
            if is_event_node(v):
                label = v[4:20] + "..." if isinstance(v, str) and v.startswith("EVT:") else str(v)[:20] + "..."
                visual_G.add_node(v, label=label, title=str(v)[4:] if isinstance(v, str) and v.startswith("EVT:") else str(v), group='Event', color='#ff7f0e', size=15)
            else:
                visual_G.add_node(v, label=str(v), group='Entity', color='#1f77b4', size=25)
        
        visual_G.add_edge(u, v, title=attr.get("title"))
        count += 1
        
def parse_dt(val: str):
    if not val:
        return None
    try:
        return datetime.fromisoformat(val.replace("Z", "+00:00"))
    except Exception:
        return None

# é¢„è®¡ç®—æ—¶é—´çº¿æ•°æ®
rows = []
co_counter = {}
if timeline_entity and timeline_entity != "(è¯·é€‰æ‹©)":
    if kg_timeline_data:
        for evt in kg_timeline_data:
            ents = evt.get("entities", [])
            if timeline_entity in ents:
                t = parse_dt(evt.get("time"))
                if not t:
                    continue
                co_entities = [e for e in ents if e != timeline_entity]
                for ce in co_entities:
                    co_counter[ce] = co_counter.get(ce, 0) + 1
                rows.append({
                    "abstract": evt.get("abstract", ""),
                    "event_summary": evt.get("event_summary", ""),
                    "time_dt": t,
                    "co_entities": ", ".join(co_entities[:5]),
                    "co_entities_raw": co_entities,
                })
    else:
        for abstract, evt in events.items():
            ents = evt.get("entities", [])
            if timeline_entity in ents:
                t = parse_dt(evt.get("first_seen") or evt.get("published_at"))
                if not t:
                    continue
                co_entities = [e for e in ents if e != timeline_entity]
                for ce in co_entities:
                    co_counter[ce] = co_counter.get(ce, 0) + 1
                rows.append({
                    "abstract": abstract,
                    "event_summary": evt.get("event_summary", "") or abstract,
                    "time_dt": t,
                    "co_entities": ", ".join(co_entities[:5]),
                    "co_entities_raw": co_entities,
                })
    rows = sorted(rows, key=lambda x: x["time_dt"])[:limit_events]


KG, EntityDetails, Timeline, TimelineDetails= st.tabs(["KG", "Entity Details", "Timeline", "Timeline Details"])

with KG:
    # --- PyVis æ¸²æŸ“ ---
    try:
        from pyvis.network import Network
        import tempfile
        
        net = Network(height="700px", width="100%", bgcolor="#ffffff", font_color="black")
        net.from_nx(visual_G)
        
        if physics_enabled:
            net.force_atlas_2based()
        else:
            net.toggle_physics(False)
            
        # ä¿å­˜å¹¶è¯»å–
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp:
            net.save_graph(tmp.name)
            with open(tmp.name, "r", encoding="utf-8") as f:
                html_string = f.read()
                
        components.html(html_string, height=710, scrolling=False)
        
    except ImportError:
        st.error("PyVis not installed. Run `pip install pyvis` to view the graph.")
        st.info(f"Nodes: {visual_G.number_of_nodes()}, Edges: {visual_G.number_of_edges()}")

# --- èŠ‚ç‚¹è¯¦æƒ…é¢æ¿ ---
with EntityDetails:
    if search_query != "(All / Top Nodes)":
        st.divider()
        st.subheader(f"ğŸ“˜ Entity Details: {search_query}")
        
        ent_info = entities.get(search_query, {})
        c1, c2 = st.columns(2)
        with c1:
            st.write("**Sources:**", ", ".join(ent_info.get("sources", [])))
            st.write("**First Seen:**", ent_info.get("first_seen", "N/A"))
        with c2:
            st.write("**Aliases/Forms:**", ", ".join(ent_info.get("original_forms", [])))
            
        st.write("**Related Events:**")
        # æŸ¥æ‰¾å…³è”äº‹ä»¶æ‘˜è¦
        related_evts = []
        for evt_abstract, evt_data in events.items():
            if search_query in evt_data.get('entities', []):
                related_evts.append(evt_data.get('event_summary') or evt_abstract)
                
        for evt in related_evts[:10]:
            st.text(f"â€¢ {evt}")
        if len(related_evts) > 10:
            st.caption(f"... and {len(related_evts)-10} more.")

with Timeline:
    if timeline_entity and timeline_entity != "(è¯·é€‰æ‹©)" and rows:
        try:
            from pyvis.network import Network
            from pathlib import Path
            import tempfile
            import streamlit as st

            net = Network(
                height="750px",
                width="100%",
                bgcolor="#ffffff",
                font_color="#333333",
                directed=True,
                notebook=False
            )

            # å…³é”®è®¾ç½®ï¼šåªå…³é—­ barnesHut ç‰©ç†ä¸­çš„é‡åŠ›ï¼Œè®©èŠ‚ç‚¹è¿˜èƒ½è‡ªåŠ¨æ•£å¼€ï¼Œä½†ä¸ä¹±é£
            net.force_atlas_2based()  # æˆ–è€…ç”¨ barnes_hut ä½†è°ƒå° gravity
            # æˆ–è€…æ›´æ¨èä¸‹é¢è¿™å¥—å‚æ•°ï¼ˆæœ€ç¨³å®šæœ€ç¾è§‚ï¼‰ï¼š
            net.set_options("""
            {
            "physics": {
                "enabled": true,
                "forceAtlas2Based": {
                "gravitationalConstant": -50,
                "centralGravity": 0.01,
                "springLength": 200,
                "springStrength": 0.08,
                "damping": 0.8,
                "avoidOverlap": 1
                },
                "maxVelocity": 50,
                "minVelocity": 10,
                "solver": "forceAtlas2Based",
                "timestep": 0.5,
                "stabilization": {
                "enabled": true,
                "iterations": 200,
                "updateInterval": 25
                }
            },
            "nodes": {
                "font": {
                "size": 16,
                "face": "arial"
                }
            },
            "edges": {
                "arrows": {
                "to": {
                    "enabled": true,
                    "scaleFactor": 0.5
                }
                },
                "smooth": false,
                "color": "#999999"
            }
            }
            """)

            # 1. å…ˆæ·»åŠ æ‰€æœ‰å®ä½“èŠ‚ç‚¹ï¼ˆä¸å›ºå®šä½ç½®ï¼‰
            all_entities = set()
            for r in rows:
                for ce in r.get("co_entities_raw", [])[:8]:  # é™åˆ¶ä¸€ä¸‹æ•°é‡é˜²çˆ†ç‚¸
                    all_entities.add(ce)

            for ent in all_entities:
                net.add_node(
                    f"ent_{ent}",
                    label=ent,
                    color="#1f77b4",
                    size=20,
                    shape="dot",
                    font={"color": "white", "size": 14},
                    title=ent
                )

            # 2. æ·»åŠ äº‹ä»¶èŠ‚ç‚¹ï¼šå›ºå®š x/y
            for idx, r in enumerate(rows):
                x = idx * 230
                ys = [0,60,-60]
                y = ys[idx%3]
                
                size = 30 + len(r.get("co_entities_raw", [])) * 3
                label = r.get("event_summary", "")[:50] + "..." if len(r.get("event_summary", "")) > 50 else r.get("event_summary", "")

                net.add_node(
                    f"evt_{idx}",
                    label=label,
                    title=r.get("event_summary", ""),
                    x=x,
                    y=y,
                    fixed={"x": True, "y": True},   # å›ºå®šäº‹ä»¶èŠ‚ç‚¹ä½ç½®ï¼
                    physics=False,                  # è¿™è¡Œå¾ˆå…³é”®ï¼šäº‹ä»¶èŠ‚ç‚¹ä¸å‚ä¸ç‰©ç†
                    color="#ff7f0e",
                    size=size,
                    shape="dot",
                    font={"size": 18, "color": "white"},
                    shadow=True
                )

                # æ·»åŠ è¾¹ï¼šå®ä½“ â†’ äº‹ä»¶ï¼ˆç®­å¤´æŒ‡å‘äº‹ä»¶ï¼‰
                for ce in r.get("co_entities_raw", [])[:8]:
                    net.add_edge(f"ent_{ce}", f"evt_{idx}", color="#aaaaaa", width=1.5)

            # å¯é€‰ï¼šåŠ ä¸€ä¸ªéšè—çš„â€œæ—¶é—´ä¸»çº¿â€è®©äº‹ä»¶ä¹‹é—´ä¹Ÿæœ‰è¿çº¿ï¼ˆæ›´æ¸…æ™°ï¼‰
            for i in range(len(rows)-1):
                net.add_edge(f"evt_{i}", f"evt_{i+1}", color="#ff7f0e", width=3, dashes=True)

            # ä¿å­˜å¹¶æ˜¾ç¤º
            with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp:
                net.save_graph(tmp.name)
                html_string = Path(tmp.name).read_text(encoding="utf-8")

            st.components.v1.html(html_string, height=800, scrolling=True)

        except ImportError:
            st.warning("è¯·å…ˆå®‰è£… pyvisï¼š`pip install pyvis`")


with TimelineDetails:
    st.subheader("æ—¶é—´çº¿è¯¦æƒ…")
    if timeline_entity and timeline_entity != "(è¯·é€‰æ‹©)":
        if rows:
            df_tl = pd.DataFrame(rows)
            chart = alt.Chart(df_tl).mark_line(point=True).encode(
                x="time_dt:T",
                y=alt.value(0),
                tooltip=["time_dt:T", "event_summary:N", "co_entities:N"]
            ).properties(height=120, width="container")
            st.altair_chart(chart, use_container_width=True)
            st.dataframe(df_tl[["time_dt", "event_summary", "co_entities"]], hide_index=True, use_container_width=True)
            
            if co_counter:
                top_co = sorted(co_counter.items(), key=lambda x: x[1], reverse=True)[:10]
                st.caption("Top å…±ç°å®ä½“")
                st.table({"entity": [x[0] for x in top_co], "count": [x[1] for x in top_co]})
        else:
            st.info("è¯¥å®ä½“æ²¡æœ‰å¯å±•ç¤ºçš„å¸¦æ—¶é—´äº‹ä»¶ã€‚")
    else:
        st.info("è¯·é€‰æ‹©ä¸€ä¸ªå®ä½“æŸ¥çœ‹æ—¶é—´çº¿ã€‚")





