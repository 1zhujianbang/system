"""
ä¸»æµç¨‹é¡µé¢ - ç®€åŒ–ç‰ˆ

æ ¸å¿ƒåŠŸèƒ½ï¼šä¸€é”®è¿è¡Œå¢é‡æ›´æ–°æµç¨‹
"""
from __future__ import annotations

import streamlit as st
from datetime import datetime, timezone, timedelta

from src.web import utils
from src.web.config import DATA_DIR
from src.web.components.task_monitor import render_task_monitor
from src.web.services.pipeline_runner import get_global_pipeline_runner, append_history
from src.web.framework.user_context import can_write, get_user_context, render_user_context_controls


def render() -> None:
    render_user_context_controls()
    
    # è·å–ä»»åŠ¡ç®¡ç†å™¨
    task_manager = get_global_pipeline_runner()
    
    st.info("ğŸ“° æ–°é—»å¤„ç†æµç¨‹ ï¼šä¸€é”®è¿è¡Œï¼šæŠ“å–æ–°é—» â†’ æå–å®ä½“/äº‹ä»¶ â†’ æ›´æ–°çŸ¥è¯†å›¾è°±")
    if_thirty_days = st.checkbox("ä¸‰åå¤©",value=False)
    
    # --- ä»»åŠ¡çŠ¶æ€ç›‘æ§ ---
    render_task_monitor(task_manager)
    
    st.divider()
    
    # --- æ•°æ®ç»Ÿè®¡ ---
    col1, col2, col3 = st.columns(3)
    
    with st.spinner("åŠ è½½æ•°æ®..."):
        entities = utils.load_entities() or {}
        events = utils.load_events() or {}
        news_files = utils.get_raw_news_files()
    
    with col1:
        st.metric("ğŸ“° æ–°é—»æ–‡ä»¶", len(news_files))
    with col2:
        st.metric("ğŸ§  å®ä½“æ•°é‡", len(entities))
    with col3:
        st.metric("ğŸ”— äº‹ä»¶æ•°é‡", len(events))
    
    st.divider()
    
    # --- ä¸€é”®è¿è¡Œ ---
    def execute_pipeline(pipeline_def):
        """æäº¤ä»»åŠ¡åˆ°åå°ç®¡ç†å™¨"""
        if not can_write():
            st.error("å½“å‰è§’è‰²ä¸º viewerï¼šç¦æ­¢å¯åŠ¨æµæ°´çº¿ã€‚")
            return
        if task_manager.is_running:
            st.warning("âš ï¸ å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œã€‚è¯·ç­‰å¾…å®Œæˆåå†è¯•ã€‚")
            return

        # æ¸…é™¤ç¼“å­˜
        try:
            st.cache_data.clear()
        except Exception:
            pass
        
        # è®°å½•åŸºçº¿
        st.session_state["_run_baseline"] = {
            "entities": list(entities.keys()),
            "events": list(events.keys()),
        }

        history_idx = append_history(pipeline_def)
        run_id = ""
        try:
            run_id = st.session_state.pipeline_history[history_idx].get("run_id") or ""
        except Exception:
            run_id = ""
        
        project_id = get_user_context().project_id
        success = task_manager.start(pipeline_def, history_idx=history_idx, run_id=run_id, project_id=project_id)
        
        if success:
            st.toast("ğŸš€ ä»»åŠ¡å·²å¯åŠ¨ï¼")
            st.rerun()
        else:
            try:
                if "pipeline_history" in st.session_state and 0 <= history_idx < len(st.session_state.pipeline_history):
                    st.session_state.pipeline_history.pop(history_idx)
            except Exception:
                pass
            st.error("å¯åŠ¨ä»»åŠ¡å¤±è´¥ã€‚")

    # æ„å»ºé»˜è®¤çš„å¢é‡æ›´æ–° Pipeline
    now_utc = datetime.now(timezone.utc)
    days = 30 if if_thirty_days else 1
    
    from_dt = (now_utc - timedelta(days=days)).date().isoformat()
    to_dt = now_utc.date().isoformat()
    from_val = f"{from_dt}T00:00:00.000Z"
    to_val = f"{to_dt}T23:59:59.999Z"
    # è·å–å¯ç”¨çš„æ–°é—»æº
    selected_sources = []
    df_sources = st.session_state.get("ingestion_apis")
    if df_sources is not None and not getattr(df_sources, "empty", True):
        selected_sources = df_sources[df_sources["enabled"] == True]["name"].tolist()
    
    # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æº
    if not selected_sources:
        st.session_state.ingestion_apis = utils.get_default_api_sources_df()
        df_sources = st.session_state.ingestion_apis
        selected_sources = df_sources[df_sources["enabled"] == True]["name"].tolist()

    # æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
    st.info(f"ğŸ“¡ æ•°æ®æº: {', '.join(selected_sources[:3])}{'...' if len(selected_sources) > 3 else ''} ({len(selected_sources)} ä¸ª)")
    
    # è¿è¡ŒæŒ‰é’®
    run_disabled = task_manager.is_running or (not selected_sources)

    if st.button("ğŸš€ å¼€å§‹è¿è¡Œ", type="primary", use_container_width=True, disabled=run_disabled):
        pipeline_def = {
            "name": "Incremental Update",
            "steps": [
                {
                    "id": "fetch_news",
                    "tool": "fetch_news_stream",
                    "inputs": {
                        "limit": 10,
                        "sources": selected_sources,
                        "from_": from_val,
                        "to": to_val,
                        "daily_incremental": True,  # å¯ç”¨æŒ‰å¤©é€’å¢è¯·æ±‚
                    },
                    "output": "raw_news_data",
                },
                {
                    "id": "process_news",
                    "tool": "batch_process_news",
                    "inputs": {"news_list": "$raw_news_data"},
                    "output": "extracted_events",
                },
                {
                    "id": "update_graph",
                    "tool": "append_only_update_graph",
                    "inputs": {
                        "events_list": "$extracted_events",
                        "allow_append_original_forms": True,
                    },
                    "output": "kg_update_result",
                },
                {
                    "id": "refresh_kg",
                    "tool": "refresh_knowledge_graph",
                    "inputs": {},
                    "output": "kg_refresh",
                },
                {
                    "id": "report",
                    "tool": "generate_markdown_report",
                    "inputs": {
                        "events_list": "$extracted_events",
                        "title": "Incremental Update Report",
                    },
                    "output": "final_report_md",
                },
            ],
        }
        execute_pipeline(pipeline_def)
    
    if task_manager.is_running:
        st.caption("â³ ä»»åŠ¡è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…...")
    
    st.divider()
    
    # --- è¿è¡Œç»“æœå±•ç¤º ---
    st.subheader("ğŸ“‹ è¿è¡Œç»“æœ")
    
    # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
    if task_manager.final_report:
        with st.expander("ğŸ“„ ç”Ÿæˆçš„æŠ¥å‘Š", expanded=True):
            st.markdown(task_manager.final_report)
    
    # æ˜¾ç¤ºè¿è¡Œæ—¥å¿—
    if task_manager.logs:
        with st.expander(f"ğŸ“ è¿è¡Œæ—¥å¿— ({len(task_manager.logs)} æ¡)", expanded=False):
            log_text = "\n".join(task_manager.logs[-50:])  # æœ€è¿‘50æ¡
            st.code(log_text, language="text")
    
    # æ˜¾ç¤ºè¾“å‡ºæ•°æ®
    if task_manager.last_outputs:
        with st.expander("ğŸ“Š è¾“å‡ºæ•°æ®", expanded=False):
            for key, value in task_manager.last_outputs.items():
                st.write(f"**{key}**:")
                if isinstance(value, list):
                    st.write(f"  åˆ—è¡¨ï¼Œ{len(value)} é¡¹")
                elif isinstance(value, dict):
                    st.json(value)
                else:
                    st.write(value)
