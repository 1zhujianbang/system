import torch
from ..config.config_manager import ModelConfig
from pathlib import Path
import os

def check_model_file(file_path):
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    file_path = Path(file_path)
    
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶: {file_path}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_path.stat().st_size} å­—èŠ‚")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if file_path.stat().st_size == 0:
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸ºç©º!")
        return False
    
    # å°è¯•è¯»å–æ–‡ä»¶å¤´ä¿¡æ¯
    try:
        with open(file_path, 'rb') as f:
            # PyTorch æ–‡ä»¶é€šå¸¸ä»¥ç‰¹å®šçš„é­”æœ¯æ•°å­—å¼€å¤´
            header = f.read(8)
            print(f"ğŸ” æ–‡ä»¶å¤´: {header.hex()}")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤´å¤±è´¥: {e}")
        return False
    
    return True

class ModelLoader:
    def __init__(self, models_dir: str = "./models"):
        self.models_dir = Path(models_dir)
        print(f"ğŸ“ æ¨¡å‹ç›®å½•è·¯å¾„: {self.models_dir.absolute()}")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not self.models_dir.exists():
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.models_dir}")
            # å°è¯•åˆ›å»ºç›®å½•
            self.models_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ å·²åˆ›å»ºæ¨¡å‹ç›®å½•: {self.models_dir}")

    def load_model(self, model_config: ModelConfig):
        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹ï¼Œé…ç½®: {model_config}")
        
        if model_config is None:
            raise ValueError("model_config ä¸èƒ½ä¸º None")
        
        if not hasattr(model_config, 'model_name') or not model_config.model_name:
            raise ValueError(f"model_config å¿…é¡»åŒ…å«æœ‰æ•ˆçš„ model_nameï¼Œå½“å‰: {getattr(model_config, 'model_name', 'None')}")
        
        model_path = self.models_dir / f"{model_config.model_name}"
        print(f"ğŸ” æ¨¡å‹å®Œæ•´è·¯å¾„: {model_path.absolute()}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not model_path.exists():
            # åˆ—å‡ºç›®å½•å†…å®¹å¸®åŠ©è°ƒè¯•
            print(f"ğŸ“ æ¨¡å‹ç›®å½•å†…å®¹:")
            try:
                for file in self.models_dir.iterdir():
                    print(f"   - {file.name}")
            except Exception as e:
                print(f"   æ— æ³•è¯»å–ç›®å½•: {e}")
            
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨")

        print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        
        # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
        if not check_model_file(model_path):
            raise ValueError("æ¨¡å‹æ–‡ä»¶å¯èƒ½å·²æŸå")

        # æ ¹æ®æ–‡ä»¶åç¼€ååˆ¤æ–­æ¡†æ¶å¹¶åŠ è½½
        supported_suffixes = ['.pt', '.pth', '.bin', '.ckpt']
        
        if model_path.suffix in supported_suffixes:
            try:
                print(f"ğŸ” ä½¿ç”¨ PyTorch åŠ è½½æ¨¡å‹...")
                model = torch.load(model_path, map_location='cpu')
                print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                
                if hasattr(model, 'eval'):
                    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                    print("âœ… æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼")
                    
                return model
            except Exception as e:
                raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {model_path.suffix}ã€‚æ”¯æŒçš„æ ¼å¼: {supported_suffixes}")