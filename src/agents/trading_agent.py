from ..config.config_manager import TradingConfig
from ..models.model_loader import ModelLoader
from ..data.data_collector import OKXMarketClient
from ..data.news_collector import BlockbeatsNewsCollector, NewsType, Language
from ..agents.agent1 import process_news_stream, ENTITIES_FILE, ABSTRACT_MAP_FILE, RAW_NEWS_DIR
from datetime import datetime, timezone
import re
import pandas as pd
import json
import os
from pathlib import Path
import uuid

class TradingAgent:
    def __init__(self, config: TradingConfig):
        self.config = config
        self.model = None
        self.portfolio = {
            'cash': config.user_config.cash,
            'positions': {},
        }
        self.is_ready = False
        self._cleanup_done = False

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.okx_client = OKXMarketClient(config.user_config, config.data_config)
        self.news_collector = BlockbeatsNewsCollector(language=Language.CN)

        # æ•°æ®å­˜å‚¨
        self.market_data = {}
        self.realtime_data = {}
        self.technical_data = {}
        self.news_data = {}
        self.market_sentiment = {}

    async def initialize(self):
        """åˆå§‹åŒ–Agentçš„æ ¸å¿ƒæµç¨‹"""
        print("Initializing AI Trading Agent...")

        try:
             # 1. éªŒè¯é…ç½®
            print("ğŸ” éªŒè¯æ¨¡å‹é…ç½®...")
            if not hasattr(self.config, 'modeL_config'):
                raise ValueError("é…ç½®ä¸­ç¼ºå°‘ modeL_config å­—æ®µ")
            
            if self.config.modeL_config is None:
                raise ValueError("modeL_config ä¸º None")
            
            print(f"âœ… æ¨¡å‹é…ç½®å­˜åœ¨: {self.config.modeL_config.model_name}")

            # 2. åŠ è½½æ¨¡å‹
            print("ğŸ” åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨...")
            model_loader = ModelLoader()
            print(f"ğŸ” æ¨¡å‹ç›®å½•: {model_loader.models_dir}")
            print(f"ğŸ” æ¨¡å‹åç§°: {self.config.modeL_config.model_name}")
            
            print("ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹...")
            self.model = model_loader.load_model(self.config.modeL_config)
            print(f"âœ… Model {self.config.modeL_config.model_name} loaded successfully.")

            # 3. äº¤æ˜“æ•°æ®åˆå§‹åŒ– 
            # self._initialize_trading_data()

            # 4. æ–°é—»æ•°æ®åˆå§‹åŒ–
            await self._initialize_news_data()

            # 5. åˆå§‹åŒ–æ•°æ®æµ (ä¼ªä»£ç )
            # self.data_stream = DataStream(self.config.user_config.trading_pairs)

            # 6. æ ‡è®°ä¸ºå°±ç»ªçŠ¶æ€
            self.is_ready = True
            print("AI Trading Agent is now READY.")

        except Exception as e:
            print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {str(e)}")
            import traceback
            print("ğŸ” è¯¦ç»†å †æ ˆè·Ÿè¸ª:")
            traceback.print_exc()
            raise

    def get_status(self):
        structured_news = self.news_data.get('structured', pd.DataFrame())
        return {
            "is_ready": self.is_ready,
            "cash": self.config.user_config.cash,
            "risk_appetite": self.config.user_config.risk_appetite,
            "model_used": self.config.modeL_config.model_name,
            "market_sentiment": self.market_sentiment.get('sentiment', 'neutral'),
            "news_count": len(structured_news),
            "entities_extracted": sum(len(ents) for ents in structured_news.get('entities', [])),
            "breaking_news": self.market_sentiment.get('breaking_news_count', 0),
        }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._cleanup_done:
            return
        print("ğŸ§¹ æ¸…ç†äº¤æ˜“Agentèµ„æº...")
        try:
            if hasattr(self.news_collector, 'close'):
                await self.news_collector.close()
            elif hasattr(self.news_collector, 'session') and self.news_collector.session:
                await self.news_collector.session.close()
        except Exception as e:
            print(f"âš ï¸ èµ„æºæ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        finally:
            self._cleanup_done = True

    def _initialize_trading_data(self):
        """åˆå§‹åŒ–äº¤æ˜“æ•°æ®"""
        print("åˆå§‹åŒ–äº¤æ˜“æ•°æ®...")
        
        # 3.1 éªŒè¯äº¤æ˜“å¯¹é…ç½®
        trading_pairs = self.okx_client.get_trading_pairs()
        print(f"é…ç½®çš„äº¤æ˜“å¯¹: {trading_pairs}")
        
        if not trading_pairs:
            raise ValueError("æœªé…ç½®äº¤æ˜“å¯¹")
        
        # 3.2 è·å–å®æ—¶æ•°æ®
        print("è·å–å®æ—¶è¡Œæƒ…æ•°æ®...")
        self.realtime_data = self.okx_client.get_all_tickers_with_changes() 
        print(f"æˆåŠŸè·å– {len(self.realtime_data)} ä¸ªäº¤æ˜“å¯¹çš„å®æ—¶æ•°æ®")
        
        # éªŒè¯å®æ—¶æ•°æ®
        for pair in trading_pairs:
            if pair not in self.realtime_data:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•è·å– {pair} çš„å®æ—¶æ•°æ®")
        
        # 3.3 è·å–å†å²Kçº¿æ•°æ®
        print("è·å–å†å²Kçº¿æ•°æ®...")
        self.market_data = self.okx_client.get_all_historical_klines()
        print(f"æˆåŠŸè·å– {len(self.market_data)} ä¸ªäº¤æ˜“å¯¹çš„å†å²æ•°æ®")
        
        # éªŒè¯å†å²æ•°æ®å®Œæ•´æ€§
        self._validate_market_data()
        
        # 3.4 åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        print("è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        self._initialize_technical_data()
        
        # 3.5 æ‰“å°æ•°æ®ç»Ÿè®¡
        self._print_data_statistics()

    def _validate_market_data(self):
        """éªŒè¯å¸‚åœºæ•°æ®å®Œæ•´æ€§"""
        for pair, data in self.market_data.items():
            if data.empty:
                print(f"âš ï¸  è­¦å‘Š: {pair} å†å²æ•°æ®ä¸ºç©º")
                continue
                
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
            min_data_points = self.config.modeL_config.data_window
            if len(data) < min_data_points:
                print(f"âš ï¸  è­¦å‘Š: {pair} æ•°æ®ç‚¹ä¸è¶³ ({len(data)} < {min_data_points})")
            
            # æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´
            time_range = data.index[-1] - data.index[0]
            print(f"   {pair}: {len(data)} æ ¹Kçº¿, æ—¶é—´èŒƒå›´: {time_range.days}å¤©")

    def _initialize_technical_data(self):
        """åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        from ..analysis.technical_calculator import TechnicalCalculator
        
        # åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨
        tech_calculator = TechnicalCalculator()
        
        for pair, data in self.market_data.items():
            if not data.empty:
                try:
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    self.technical_data[pair] = tech_calculator.calculate_all_indicators(data)
                    
                    # éªŒè¯æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                    required_features = self.config.modeL_config.features
                    missing_features = tech_calculator.validate_features(
                        self.technical_data[pair], required_features
                    )
                    
                    if missing_features:
                        print(f"âš ï¸  è­¦å‘Š: {pair} ç¼ºå°‘ç‰¹å¾ {missing_features}")
                    else:
                        print(f"âœ… {pair} æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆï¼ŒåŒ…å« {len(self.technical_data[pair].columns)} ä¸ªç‰¹å¾")
                        
                except Exception as e:
                    print(f"âŒ {pair} æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
                    # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè‡³å°‘ä¿ç•™åŸå§‹æ•°æ®
                    self.technical_data[pair] = data



    def _print_data_statistics(self):
        """æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®åˆå§‹åŒ–å®Œæˆ:")
        print(f"   äº¤æ˜“å¯¹æ•°é‡: {len(self.market_data)}")
        print(f"   æ—¶é—´æ¡†æ¶: {self.okx_client.get_timeframe()}")
        print(f"   å†å²å¤©æ•°: {self.okx_client.get_historical_days()}")
        
        total_bars = sum(len(data) for data in self.market_data.values())
        print(f"   æ€»Kçº¿æ•°é‡: {total_bars}")
        
        # æ˜¾ç¤ºæ¯ä¸ªäº¤æ˜“å¯¹çš„æœ€æ–°ä»·æ ¼
        print("\n   æœ€æ–°ä»·æ ¼:")
        tickers_with_changes = self.okx_client.get_all_tickers_with_changes()
        for pair, ticker in tickers_with_changes.items():
            if ticker:
                display_str = self.okx_client.format_price_display(ticker)
                print(f"     {display_str}")

    async def _initialize_news_data(self):
        """åˆå§‹åŒ–æ–°é—»æ•°æ®ï¼šé€šè¿‡ agent1 å¤„ç†"""
        print("ğŸ“° åˆå§‹åŒ–æ–°é—»æ•°æ®ï¼ˆè°ƒç”¨ Agent1ï¼‰...")
        try:
            # 1. è·å–åŸå§‹æ–°é—»
            important_news = await self.news_collector.get_latest_important_news(limit=5)
            if not important_news:
                print("ğŸ“­ æœªè·å–åˆ°é‡è¦æ–°é—»")
                self.news_data['structured'] = pd.DataFrame()
                self.market_sentiment = self._analyze_market_sentiment_from_df(pd.DataFrame())
                return

            # 2. ç”Ÿæˆå”¯ä¸€ä¸´æ—¶æ–‡ä»¶å
            temp_filename = f"temp_{uuid.uuid4().hex}.jsonl"
            raw_file = RAW_NEWS_DIR / temp_filename

            # 3. å†™å…¥ raw_news ç›®å½•ï¼ˆä¾› agent1 è¯»å–ï¼‰
            with open(raw_file, "w", encoding="utf-8") as f:
                for idx, news in enumerate(important_news):
                    # âœ… æ­£ç¡®å¤„ç† dict ç±»å‹çš„æ–°é—»
                    title = news.get('title', '').strip()
                    content_raw = news.get('content', '').strip()
                    
                    # æ¸…ç† HTMLï¼ˆé¿å… <p>, <br> å¹²æ‰°å»é‡å’Œ LLMï¼‰
                    clean_content = re.sub(r'<[^>]+>', '', content_raw).strip()
                    final_content = clean_content or title  # å…œåº•
                    
                    item = {
                        "id": str(news.get("id", f"temp_{idx}")),
                        "title": title,
                        "content": final_content,
                        "source": "blockbeats",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
                    f.write(json.dumps(item, ensure_ascii=False) + "\n")

            print(f"âœ… å†™å…¥ {len(important_news)} æ¡æ–°é—»åˆ° {raw_file.name}")

            # 4. è°ƒç”¨ agent1 ä¸»æµç¨‹
            process_news_stream()

            # 5. ä» agent1 è¾“å‡ºæ–‡ä»¶æ„å»ºç»“æ„åŒ– DataFrame
            df_structured = self._build_structured_news_from_agent1_output()

            # 6. ä¿å­˜å¹¶åˆ†æ
            self.news_data['structured'] = df_structured
            self.market_sentiment = self._analyze_market_sentiment_from_df(df_structured)

            # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                raw_file.unlink()
                print(f"ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {raw_file.name}")
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {e}")

            # 8. æ‰“å°æ‘˜è¦
            self._print_news_summary()

        except Exception as e:
            print(f"âŒ æ–°é—»æ•°æ®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            self.news_data = {'structured': pd.DataFrame(), 'error': str(e)}
            self.market_sentiment = self._analyze_market_sentiment_from_df(pd.DataFrame())
    
    def _build_structured_news_from_agent1_output(self) -> pd.DataFrame:
        """ä» agent1 ç”Ÿæˆçš„ abstract_map.json æ„å»ºç»“æ„åŒ– DataFrame"""
        if not ABSTRACT_MAP_FILE.exists():
            return pd.DataFrame()

        with open(ABSTRACT_MAP_FILE, "r", encoding="utf-8") as f:
            abstract_map = json.load(f)

        records = []
        for abstract, data in abstract_map.items():
            records.append({
                "abstract": abstract,
                "entities": data["entities"],
                "event_summary": data["event_summary"],
                "sources": data["sources"],
                "first_seen": data["first_seen"]
            })

        if not records:
            return pd.DataFrame()

        df = pd.DataFrame(records)
        df["title"] = df["abstract"]
        df["content"] = df["event_summary"]
        df["id"] = df.index.astype(str)
        return df

    def _analyze_market_sentiment_from_df(self, df: pd.DataFrame) -> dict:
        if df.empty:
            return {
                'sentiment_score': 0,
                'sentiment': 'neutral',
                'breaking_news_count': 0,
                'top_entities': [],
                'total_news': 0,
                'last_updated': datetime.now(timezone.utc)
            }

        # å®ä½“ç»Ÿè®¡ï¼ˆç”¨äºæƒ…ç»ªä»£ç†ï¼‰
        all_entities = []
        for ents in df['entities'].dropna():
            all_entities.extend(ents)
        from collections import Counter
        entity_freq = Counter(all_entities)
        top_entities = [ent for ent, _ in entity_freq.most_common(10)]

        # ç®€åŒ–æƒ…ç»ªï¼šä»…åŸºäºæ–°é—»æ•°é‡ï¼ˆæˆ–å¯åç»­æ¥å…¥LLMæƒ…æ„Ÿæ‰“åˆ†ï¼‰
        total_news = len(df)
        sentiment_score = total_news  # æˆ–è®¾ä¸º 0 è¡¨ç¤ºä¸­æ€§
        sentiment = 'active' if total_news > 5 else 'quiet'

        return {
            'sentiment_score': sentiment_score,
            'sentiment': sentiment,
            'breaking_news_count': total_news,
            'top_entities': top_entities,
            'total_news': total_news,
            'last_updated': datetime.now(timezone.utc)
        }

    def _print_news_summary(self):
        sentiment = self.market_sentiment
        df = self.news_data.get('structured', pd.DataFrame())
        
        print("\nğŸ“° æ–°é—»æ•°æ®æ‘˜è¦:")
        print(f"   æ€»æ–°é—»æ•°: {sentiment.get('total_news', 0)}")
        print(f"   å¸‚åœºæ´»è·ƒåº¦: {sentiment.get('sentiment', 'unknown')}")
        print(f"   é‡å¤§æ–°é—»: {sentiment.get('breaking_news_count', 0)} æ¡")
        print(f"   é«˜é¢‘å®ä½“: {', '.join(sentiment.get('top_entities', [])[:5])}")

        if not df.empty:
            print("\n   æœ€æ–°ç»“æ„åŒ–æ–°é—»:")
            for _, row in df.head(5).iterrows():
                title = row.get('abstract', '')[:60]
                entities = ', '.join(row.get('entities', []))
                print(f"     {title} | å®ä½“: {entities}")

    async def update_news_data(self):
        """æ›´æ–°æ–°é—»æ•°æ®ï¼ˆå¤ç”¨åˆå§‹åŒ–é€»è¾‘ï¼‰"""
        if not self.is_ready:
            return
        print("ğŸ”„ æ›´æ–°æ–°é—»æ•°æ®...")
        await self._initialize_news_data()
        print("âœ… æ–°é—»æ•°æ®æ›´æ–°å®Œæˆ")
    
    # ======================
    # ğŸ§  æ™ºèƒ½ä½“2 & çŸ¥è¯†å›¾è°± å ä½åŒº
    # ======================

    async def _expand_news_with_kg(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã€å ä½ã€‘æ™ºèƒ½ä½“2ï¼šåŸºäºçŸ¥è¯†å›¾è°±æ‰©å±•ç›¸å…³æ–°é—»
        è¾“å…¥ï¼šå« entities çš„ DataFrame
        è¾“å‡ºï¼šå¢å¼ºåçš„ DataFrameï¼ˆå« expanded_entities, related_news_ids ç­‰ï¼‰
        """
        # TODO: å®ç°åŸºäº Neo4j / å†…å­˜å›¾çš„å…³è”æ‰©å±•
        print("ğŸš§ æ™ºèƒ½ä½“2ï¼ˆKGæ‰©å±•ï¼‰å°šæœªå®ç°")
        return df

    def _build_temporal_knowledge_graph(self):
        """
        ã€å ä½ã€‘æ„å»ºæ—¶åºçŸ¥è¯†å›¾è°±ï¼ˆç”¨äºè·¯å¾„æ¨ç†ï¼‰
        """
        print("ğŸš§ çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—å°šæœªå®ç°")
        pass

    async def update_knowledge_graph(self):
        """
        ã€å ä½ã€‘ä¸»å…¥å£ï¼šæ›´æ–°çŸ¥è¯†å›¾è°±
        """
        if not self.is_ready or self.news_data.get('structured') is None:
            return
        await self._expand_news_with_kg(self.news_data['structured'])
        self._build_temporal_knowledge_graph()