from ..config.config_manager import TradingConfig
from ..models.model_loader import ModelLoader
from ..data.data_collector import OKXMarketClient
from ..data.news_collector import BlockbeatsNewsCollector, NewsType, Language
from ..agents.agent1 import Agent1EntityExtractor
from datetime import datetime, timezone
import re
import pandas as pd

class TradingAgent:
    def __init__(self, config: TradingConfig):
        self.config = config
        self.model = None
        self.portfolio = {
            # ä½™é¢
            'cash': config.user_config.cash,
            # æŒä»“
            'positions': {},
        }
        self.is_ready = False
        self._cleanup_done = False

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.okx_client = OKXMarketClient(config.user_config, config.data_config)
        self.news_collector = BlockbeatsNewsCollector(language=Language.CN)
        self.agent1 = None

        # æ•°æ®å­˜å‚¨
        self.market_data = {}  # å†å²Kçº¿æ•°æ®
        self.realtime_data = {}  # å®æ—¶è¡Œæƒ…æ•°æ®
        self.technical_data = {}  # æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        self.news_data = {}  # æ–°é—»æ•°æ®
        self.market_sentiment = {}  # å¸‚åœºæƒ…ç»ªåˆ†æ

    async def initialize(self):
        """åˆå§‹åŒ–Agentçš„æ ¸å¿ƒæµç¨‹"""
        print("Initializing AI Trading Agent...")

        try:
             # 1. éªŒè¯é…ç½®
            print("ğŸ” éªŒè¯æ¨¡å‹é…ç½®...")
            if not hasattr(self.config, 'modeL_config'):
                raise ValueError("é…ç½®ä¸­ç¼ºå°‘ modeL_config å­—æ®µ")
            
            if self.config.modeL_config is None:
                raise ValueError("modeL_config ä¸º None")
            
            print(f"âœ… æ¨¡å‹é…ç½®å­˜åœ¨: {self.config.modeL_config.model_name}")

            # 2. åŠ è½½æ¨¡å‹
            print("ğŸ” åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨...")
            model_loader = ModelLoader()
            print(f"ğŸ” æ¨¡å‹ç›®å½•: {model_loader.models_dir}")
            print(f"ğŸ” æ¨¡å‹åç§°: {self.config.modeL_config.model_name}")
            
            print("ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹...")
            self.model = model_loader.load_model(self.config.modeL_config)
            print(f"âœ… Model {self.config.modeL_config.model_name} loaded successfully.")

            # 3. äº¤æ˜“æ•°æ®åˆå§‹åŒ– 
            self._initialize_trading_data()

            # 4. åŠ è½½æ™ºèƒ½ä½“1ï¼ˆå®ä½“æå–å™¨ï¼‰
            print("ğŸ” åˆå§‹åŒ–æ™ºèƒ½ä½“1ï¼ˆå®ä½“æå–å™¨ï¼‰...")
            auto_update_entities = getattr(self.config.user_config, 'auto_update_entities', False)
            self.agent1 = Agent1EntityExtractor(auto_update=auto_update_entities)
            print(f"âœ… æ™ºèƒ½ä½“1å·²å°±ç»ª (auto_update={auto_update_entities})")

            # 5. æ–°é—»æ•°æ®åˆå§‹åŒ–
            await self._initialize_news_data()

            # 6. åˆå§‹åŒ–æ•°æ®æµ (ä¼ªä»£ç )
            # self.data_stream = DataStream(self.config.user_config.trading_pairs)

            # 7. æ ‡è®°ä¸ºå°±ç»ªçŠ¶æ€
            self.is_ready = True
            print("AI Trading Agent is now READY.")

        except Exception as e:
            print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {str(e)}")
            import traceback
            print("ğŸ” è¯¦ç»†å †æ ˆè·Ÿè¸ª:")
            traceback.print_exc()
            raise

    def get_status(self):
        structured_news = self.news_data.get('structured', pd.DataFrame())
        return {
            "is_ready": self.is_ready,
            "cash": self.config.user_config.cash,
            "risk_appetite": self.config.user_config.risk_appetite,
            "model_used": self.config.modeL_config.model_name,
            "market_sentiment": self.market_sentiment.get('sentiment', 'neutral'),
            "news_count": len(structured_news),
            "entities_extracted": sum(len(ents) for ents in structured_news.get('entities', [])),
            "breaking_news": self.market_sentiment.get('breaking_news_count', 0),
            "event_types": self.market_sentiment.get('event_distribution', {})
        }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº - æ˜¾ç¤ºå…³é—­æ‰€æœ‰å®¢æˆ·ç«¯ä¼šè¯"""
        if self._cleanup_done:
            return
            
        print("ğŸ§¹ æ¸…ç†äº¤æ˜“Agentèµ„æº...")
        
        try:
            # 1. å…³é—­æ–°é—»æ”¶é›†å™¨çš„ä¼šè¯
            if hasattr(self.news_collector, 'close'):
                await self.news_collector.close()
                print("âœ… æ–°é—»æ”¶é›†å™¨ä¼šè¯å·²å…³é—­")
            elif hasattr(self.news_collector, 'session') and self.news_collector.session:
                await self.news_collector.session.close()
                print("âœ… æ–°é—»æ”¶é›†å™¨ä¼šè¯å·²å…³é—­")
            
            # 2. æ‹“å±•

        except Exception as e:
            print(f"âš ï¸ èµ„æºæ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        finally:
            self._cleanup_done = True

    def _initialize_trading_data(self):
        """åˆå§‹åŒ–äº¤æ˜“æ•°æ®"""
        print("åˆå§‹åŒ–äº¤æ˜“æ•°æ®...")
        
        # 3.1 éªŒè¯äº¤æ˜“å¯¹é…ç½®
        trading_pairs = self.okx_client.get_trading_pairs()
        print(f"é…ç½®çš„äº¤æ˜“å¯¹: {trading_pairs}")
        
        if not trading_pairs:
            raise ValueError("æœªé…ç½®äº¤æ˜“å¯¹")
        
        # 3.2 è·å–å®æ—¶æ•°æ®
        print("è·å–å®æ—¶è¡Œæƒ…æ•°æ®...")
        self.realtime_data = self.okx_client.get_all_tickers_with_changes() 
        print(f"æˆåŠŸè·å– {len(self.realtime_data)} ä¸ªäº¤æ˜“å¯¹çš„å®æ—¶æ•°æ®")
        
        # éªŒè¯å®æ—¶æ•°æ®
        for pair in trading_pairs:
            if pair not in self.realtime_data:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•è·å– {pair} çš„å®æ—¶æ•°æ®")
        
        # 3.3 è·å–å†å²Kçº¿æ•°æ®
        print("è·å–å†å²Kçº¿æ•°æ®...")
        self.market_data = self.okx_client.get_all_historical_klines()
        print(f"æˆåŠŸè·å– {len(self.market_data)} ä¸ªäº¤æ˜“å¯¹çš„å†å²æ•°æ®")
        
        # éªŒè¯å†å²æ•°æ®å®Œæ•´æ€§
        self._validate_market_data()
        
        # 3.4 åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        print("è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        self._initialize_technical_data()
        
        # 3.5 æ‰“å°æ•°æ®ç»Ÿè®¡
        self._print_data_statistics()

    def _validate_market_data(self):
        """éªŒè¯å¸‚åœºæ•°æ®å®Œæ•´æ€§"""
        for pair, data in self.market_data.items():
            if data.empty:
                print(f"âš ï¸  è­¦å‘Š: {pair} å†å²æ•°æ®ä¸ºç©º")
                continue
                
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
            min_data_points = self.config.modeL_config.data_window
            if len(data) < min_data_points:
                print(f"âš ï¸  è­¦å‘Š: {pair} æ•°æ®ç‚¹ä¸è¶³ ({len(data)} < {min_data_points})")
            
            # æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´
            time_range = data.index[-1] - data.index[0]
            print(f"   {pair}: {len(data)} æ ¹Kçº¿, æ—¶é—´èŒƒå›´: {time_range.days}å¤©")

    def _initialize_technical_data(self):
        """åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        from ..analysis.technical_calculator import TechnicalCalculator
        
        # åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨
        tech_calculator = TechnicalCalculator()
        
        for pair, data in self.market_data.items():
            if not data.empty:
                try:
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    self.technical_data[pair] = tech_calculator.calculate_all_indicators(data)
                    
                    # éªŒè¯æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                    required_features = self.config.modeL_config.features
                    missing_features = tech_calculator.validate_features(
                        self.technical_data[pair], required_features
                    )
                    
                    if missing_features:
                        print(f"âš ï¸  è­¦å‘Š: {pair} ç¼ºå°‘ç‰¹å¾ {missing_features}")
                    else:
                        print(f"âœ… {pair} æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆï¼ŒåŒ…å« {len(self.technical_data[pair].columns)} ä¸ªç‰¹å¾")
                        
                except Exception as e:
                    print(f"âŒ {pair} æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
                    # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè‡³å°‘ä¿ç•™åŸå§‹æ•°æ®
                    self.technical_data[pair] = data



    def _print_data_statistics(self):
        """æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®åˆå§‹åŒ–å®Œæˆ:")
        print(f"   äº¤æ˜“å¯¹æ•°é‡: {len(self.market_data)}")
        print(f"   æ—¶é—´æ¡†æ¶: {self.okx_client.get_timeframe()}")
        print(f"   å†å²å¤©æ•°: {self.okx_client.get_historical_days()}")
        
        total_bars = sum(len(data) for data in self.market_data.values())
        print(f"   æ€»Kçº¿æ•°é‡: {total_bars}")
        
        # æ˜¾ç¤ºæ¯ä¸ªäº¤æ˜“å¯¹çš„æœ€æ–°ä»·æ ¼
        print("\n   æœ€æ–°ä»·æ ¼:")
        tickers_with_changes = self.okx_client.get_all_tickers_with_changes()
        for pair, ticker in tickers_with_changes.items():
            if ticker:
                display_str = self.okx_client.format_price_display(ticker)
                print(f"     {display_str}")

    async def _initialize_news_data(self):
        """åˆå§‹åŒ–æ–°é—»æ•°æ®"""
        print("ğŸ“° åˆå§‹åŒ–æ–°é—»æ•°æ®...")
    
        try:
            # ä½¿ç”¨æ ¸å¿ƒæ›´æ–°é€»è¾‘
            await self._update_news_core()
            
            # åˆå§‹åŒ–ç‰¹å®šçš„è®¾ç½®
            self.news_data['initialized'] = True
            self.news_data['first_init_time'] = datetime.now(timezone.utc)
            
            # æ‰“å°æ–°é—»æ‘˜è¦
            self._print_news_summary()
            
        except Exception as e:
            print(f"âŒ æ–°é—»æ•°æ®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.news_data = {
                'important': [], 
                'error': str(e),
                'initialized': False
            }
    
    def _analyze_market_sentiment_from_df(self, df: pd.DataFrame) -> dict:
        """
        åŸºäºæ™ºèƒ½ä½“1è¾“å‡ºçš„ç»“æ„åŒ–æ–°é—»DataFrameåˆ†æå¸‚åœºæƒ…ç»ª
        è¾“å…¥: åŒ…å« 'event_type', 'entities' åˆ—çš„DataFrame
        """
        if df.empty:
            return {
                'sentiment_score': 0,
                'sentiment': 'neutral',
                'breaking_news_count': 0,
                'top_entities': [],
                'event_distribution': {},
                'total_news': 0,
                'last_updated': datetime.now(timezone.utc)
            }

        # 1. äº‹ä»¶ç±»å‹åˆ†å¸ƒï¼ˆç”¨äºæƒ…ç»ªå€¾å‘ï¼‰
        event_counts = df['event_type'].value_counts().to_dict()
        
        # 2. æƒ…ç»ªæ˜ å°„ï¼ˆå¯é…ç½®ï¼‰
        BULLISH_EVENTS = {'listing', 'partnership', 'upgrade', 'adoption'}
        BEARISH_EVENTS = {'regulation', 'hack', 'market'}  # market å¯èƒ½ä¸­æ€§ï¼Œæ­¤å¤„æš‚å½’è´Ÿé¢
        
        bullish_score = sum(count for et, count in event_counts.items() if et in BULLISH_EVENTS)
        bearish_score = sum(count for et, count in event_counts.items() if et in BEARISH_EVENTS)
        
        sentiment_score = bullish_score - bearish_score
        
        if sentiment_score > 1:
            sentiment = 'bullish'
        elif sentiment_score < -1:
            sentiment = 'bearish'
        else:
            sentiment = 'neutral'

        # 3. æå–é«˜é¢‘å®ä½“ï¼ˆå‰10ï¼‰
        all_entities = [ent for ents in df['entities'].dropna() for ent in ents]
        from collections import Counter
        entity_freq = Counter(all_entities)
        top_entities = [ent for ent, _ in entity_freq.most_common(10)]

        # 4. é‡å¤§æ–°é—»è®¡æ•°ï¼ˆå®šä¹‰ï¼šé None event_type å³è§†ä¸ºé‡è¦ï¼‰
        breaking_news_count = df['event_type'].notna().sum()

        return {
            'sentiment_score': sentiment_score,
            'sentiment': sentiment,
            'breaking_news_count': int(breaking_news_count),
            'top_entities': top_entities,
            'event_distribution': event_counts,
            'total_news': len(df),
            'last_updated': datetime.now(timezone.utc)
        }

    def _print_news_summary(self):
        """æ‰“å°æ–°é—»æ‘˜è¦ï¼ˆåŸºäºç»“æ„åŒ–æ•°æ®ï¼‰"""
        sentiment = self.market_sentiment
        df = self.news_data.get('structured', pd.DataFrame())
        
        print("\nğŸ“° æ–°é—»æ•°æ®æ‘˜è¦:")
        print(f"   æ€»æ–°é—»æ•°: {sentiment.get('total_news', 0)}")
        print(f"   å¸‚åœºæƒ…ç»ª: {sentiment.get('sentiment', 'unknown')} (åˆ†æ•°: {sentiment.get('sentiment_score', 0)})")
        print(f"   é‡å¤§æ–°é—»: {sentiment.get('breaking_news_count', 0)} æ¡")
        print(f"   é«˜é¢‘å®ä½“: {', '.join(sentiment.get('top_entities', [])[:5])}")
        print(f"   äº‹ä»¶åˆ†å¸ƒ: {sentiment.get('event_distribution', {})}")

        # æ˜¾ç¤ºæœ€æ–°3æ¡å¸¦å®ä½“çš„æ–°é—»
        if not df.empty:
            print("\n   æœ€æ–°ç»“æ„åŒ–æ–°é—»:")
            for _, row in df.head(3).iterrows():
                title = row.get('title', 'æ— æ ‡é¢˜')
                if len(title) > 60:
                    title = title[:57] + '...'
                entities = ', '.join(row['entities']) if row['entities'] else 'æ— '
                event = row['event_type'] or 'unknown'
                print(f"     [{event}] {title} | å®ä½“: {entities}")

    async def _update_news_core(self):
        """æ–°é—»æ•°æ®æ ¸å¿ƒæ›´æ–°é€»è¾‘"""
        # 1. è·å–åŸå§‹æ–°é—»åˆ—è¡¨
        important_news = await self.news_collector.get_latest_important_news(limit=20)

        # 2. è½¬ä¸ºDataFrame
        df_raw = self.news_collector.news_to_dataframe(important_news)

        if df_raw.empty:
            self.news_data['structured'] = pd.DataFrame()
            self.market_sentiment = self._analyze_market_sentiment([])
            return

        # 3. è°ƒç”¨æ™ºèƒ½ä½“1è¿›è¡Œå®ä½“ä¸äº‹ä»¶ç±»å‹æå–
        df_enriched = self.agent1.process(df_raw)

        # 4. ä¿å­˜ç»“æ„åŒ–æ–°é—»æ•°æ®
        self.news_data['structured'] = df_enriched

        # 5. æ›´æ–°å¸‚åœºæƒ…ç»ª
        self.market_sentiment = self._analyze_market_sentiment_from_df(df_enriched)

        # 6. ï¼ˆå¯é€‰ï¼‰ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹ä¿å­˜å…³è”æ–°é—»ï¼ˆåç»­å¯åŸºäº entities è¿‡æ»¤ï¼‰
        trading_pairs = self.okx_client.get_trading_pairs()
        for pair in trading_pairs:
            symbol = pair.split('-')[0].upper()
            # å ä½ï¼šåç»­å¯ç”±æ™ºèƒ½ä½“2åŸºäºå›¾è°±æ‰©å±•
            self.news_data[pair] = {
                'symbol': symbol,
                'related_entities': [symbol],  # åˆå§‹å‡è®¾ç¬¦å·å³å®ä½“
                'news_df': df_enriched[df_enriched['entities'].apply(lambda ents: symbol in ents)]
            }

    async def update_news_data(self):
        """æ›´æ–°æ–°é—»æ•°æ®"""
        if not self.is_ready:
            return
        
        try:
            print("ğŸ”„ æ›´æ–°æ–°é—»æ•°æ®...")
            
            # ä½¿ç”¨å…±ç”¨çš„æ ¸å¿ƒæ›´æ–°é€»è¾‘
            await self._update_news_core()
            
            # æ›´æ–°ç‰¹å®šçš„å¤„ç†
            self.news_data['last_updated'] = datetime.now(timezone.utc)
            self.news_data['update_count'] = self.news_data.get('update_count', 0) + 1
        
            self._print_news_summary()
            
            print(f"âœ… æ–°é—»æ•°æ®æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ–°é—»æ•°æ®æ›´æ–°å¤±è´¥: {str(e)}")
            self.news_data['last_update_error'] = str(e)

    # ======================
    # ğŸ§  æ™ºèƒ½ä½“2 & çŸ¥è¯†å›¾è°± å ä½åŒº
    # ======================

    async def _expand_news_with_kg(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã€å ä½ã€‘æ™ºèƒ½ä½“2ï¼šåŸºäºçŸ¥è¯†å›¾è°±æ‰©å±•ç›¸å…³æ–°é—»
        è¾“å…¥ï¼šå« entities çš„ DataFrame
        è¾“å‡ºï¼šå¢å¼ºåçš„ DataFrameï¼ˆå« expanded_entities, related_news_ids ç­‰ï¼‰
        """
        # TODO: å®ç°åŸºäº Neo4j / å†…å­˜å›¾çš„å…³è”æ‰©å±•
        print("ğŸš§ æ™ºèƒ½ä½“2ï¼ˆKGæ‰©å±•ï¼‰å°šæœªå®ç°")
        return df

    def _build_temporal_knowledge_graph(self):
        """
        ã€å ä½ã€‘æ„å»ºæ—¶åºçŸ¥è¯†å›¾è°±ï¼ˆç”¨äºè·¯å¾„æ¨ç†ï¼‰
        """
        print("ğŸš§ çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—å°šæœªå®ç°")
        pass

    async def update_knowledge_graph(self):
        """
        ã€å ä½ã€‘ä¸»å…¥å£ï¼šæ›´æ–°çŸ¥è¯†å›¾è°±
        """
        if not self.is_ready or self.news_data.get('structured') is None:
            return
        await self._expand_news_with_kg(self.news_data['structured'])
        self._build_temporal_knowledge_graph()