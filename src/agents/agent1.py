# src/agents/agent1.py
"""
Agent1: æ–°é—»å®ä½“æå–ä»£ç†

è¯¥ä»£ç†è´Ÿè´£ä»æ–°é—»ä¸­æå–å®ä½“å’Œäº‹ä»¶ä¿¡æ¯ã€‚
æ ¸å¿ƒé€»è¾‘å·²é‡æ„åˆ° functions/extraction.py ä¸­å®ç°è§£è€¦åˆã€‚
"""

from ..functions.extraction import process_news_pipeline
from ..functions.graph_ops import refresh_knowledge_graph
from ..core import ConfigManager, LoggerManager, tools
import threading
import asyncio


async def process_news_stream(max_workers: int = 3, rate_limit_per_sec: float = 1.0):
    """
    Agent1ä¸»æµç¨‹ï¼šå¤„ç†æ–°é—»ç®¡é“

    Args:
        max_workers: æœ€å¤§å¹¶å‘æ•°
        rate_limit_per_sec: æ¯ç§’é€Ÿç‡é™åˆ¶
    """
    tools.log("ğŸš€ å¯åŠ¨ Agent1ï¼šæ–°é—»å®ä½“æå–ç®¡é“")

    # è°ƒç”¨functionsä¸­çš„å¤„ç†é€»è¾‘
    result = await process_news_pipeline(
        max_workers=max_workers,
        rate_limit_per_sec=rate_limit_per_sec
    )

    tools.log(f"âœ… Agent1å®Œæˆï¼šå¤„ç†äº† {result.get('processed_count', 0)} æ¡æ–°é—»ï¼Œæ¥è‡ª {result.get('files_processed', 0)} ä¸ªæ–‡ä»¶")

    # å¦‚æœæœ‰æ–°æ•°æ®ï¼Œè§¦å‘çŸ¥è¯†å›¾è°±åˆ·æ–°
    if result.get('processed_count', 0) > 0:
        try:
            # åœ¨åå°çº¿ç¨‹ä¸­åˆ·æ–°çŸ¥è¯†å›¾è°±
            def refresh_async():
                refresh_knowledge_graph()

            with tools._refresh_lock:
                thread = threading.Thread(target=refresh_async, daemon=True)
                thread.start()
                tools.log("ğŸ”„ å·²å¯åŠ¨çŸ¥è¯†å›¾è°±åˆ·æ–°çº¿ç¨‹")
        except Exception as e:
            tools.log(f"âš ï¸ å¯åŠ¨çŸ¥è¯†å›¾è°±åˆ·æ–°å¤±è´¥: {e}")
    else:
        tools.log("ğŸ“­ æœªå¤„ç†ä»»ä½•æ–°é—»ï¼Œè·³è¿‡çŸ¥è¯†å›¾è°±åˆ·æ–°")


def run_agent1():
    """
    åŒæ­¥è¿è¡ŒAgent1ï¼ˆä¾›å‘½ä»¤è¡Œè°ƒç”¨ï¼‰
    """
    import asyncio

    # è·å–é…ç½®
    config_manager = ConfigManager()
    max_workers = config_manager.get_concurrency_limit("agent1_config")
    rate_limit = config_manager.get_rate_limit("agent1_config")

    # è¿è¡Œå¼‚æ­¥å¤„ç†
    asyncio.run(process_news_stream(
        max_workers=max_workers,
        rate_limit_per_sec=rate_limit
    ))