# src/agents/kg_interface.py
"""
çŸ¥è¯†å›¾è°±æ¥å£å‡½æ•°æ¨¡å—

æä¾›ç»Ÿä¸€çš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢å’Œæ“ä½œAPIï¼Œä½œä¸ºå…¶ä»–æ¨¡å—ä¸çŸ¥è¯†å›¾è°±äº¤äº’çš„æ¡¥æ¢
"""

from typing import Dict, List, Optional, Any
from pathlib import Path
import json
import logging

from ..utils.tool_function import tools
from .knowledge_graph import get_knowledge_graph, build_knowledge_graph

# åˆå§‹åŒ–å·¥å…·
tools = tools()

class KnowledgeGraphInterface:
    """
    çŸ¥è¯†å›¾è°±æ¥å£ç±»
    
    æä¾›é«˜å±‚APIå°è£…ï¼Œç®€åŒ–çŸ¥è¯†å›¾è°±çš„ä½¿ç”¨
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ¥å£ç±»"""
        tools.log(f"ğŸ” [DEBUG] çŸ¥è¯†å›¾è°±æ¥å£åˆå§‹åŒ–å¼€å§‹...")
        try:
            self.kg = get_knowledge_graph()
            tools.log(f"ğŸ” [DEBUG] æˆåŠŸè·å–çŸ¥è¯†å›¾è°±å®ä¾‹ï¼Œå½“å‰èŠ‚ç‚¹æ•°: {len(self.kg.nodes)}")
            self._ensure_graph_loaded()
            tools.log(f"ğŸ” [DEBUG] çŸ¥è¯†å›¾è°±æ¥å£åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            tools.log(f"âŒ [DEBUG] çŸ¥è¯†å›¾è°±æ¥å£åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            tools.log(f"âŒ [DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    def _ensure_graph_loaded(self) -> None:
        """ç¡®ä¿çŸ¥è¯†å›¾è°±å·²åŠ è½½"""
        tools.log(f"ğŸ” [DEBUG] æ£€æŸ¥çŸ¥è¯†å›¾è°±åŠ è½½çŠ¶æ€ï¼Œå½“å‰èŠ‚ç‚¹æ•°: {len(self.kg.nodes)}")
        if len(self.kg.nodes) == 0:
            tools.log("ğŸ”„ çŸ¥è¯†å›¾è°±æœªåŠ è½½ï¼Œå°è¯•æ„å»º...")
            try:
                tools.log(f"ğŸ” [DEBUG] å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±...")
                build_knowledge_graph()
                tools.log(f"âœ… [DEBUG] çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼Œæ›´æ–°åèŠ‚ç‚¹æ•°: {len(self.kg.nodes)}")
            except Exception as e:
                tools.log(f"âŒ æ„å»ºçŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
                import traceback
                tools.log(f"âŒ [DEBUG] æ„å»ºå¤±è´¥é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    def search_entity(self, entity_name: str) -> Optional[Dict[str, Any]]:
        """
        æœç´¢å®ä½“ä¿¡æ¯
        
        Args:
            entity_name: å®ä½“åç§°
            
        Returns:
            å®ä½“è¯¦æƒ…å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        import time
        start_time = time.time()
        tools.log(f"ğŸ” [DEBUG] æœç´¢å®ä½“: '{entity_name}'")
        
        try:
            entity_info = self.kg.get_entity_info(entity_name)
            processing_time = (time.time() - start_time) * 1000
            
            if entity_info:
                result = {
                    "id": entity_info["id"],
                    "name": entity_info["name"],
                    "type": entity_info["properties"].get("entity_type", "entity"),
                    "first_seen": entity_info["first_seen"],
                    "sources": entity_info["sources"],
                    "original_forms": entity_info["original_forms"]
                }
                tools.log(f"âœ… [DEBUG] æ‰¾åˆ°å®ä½“: '{entity_name}'ï¼Œè€—æ—¶: {processing_time:.2f}ms")
                return result
            else:
                tools.log(f"âš ï¸ [DEBUG] æœªæ‰¾åˆ°å®ä½“: '{entity_name}'ï¼Œè€—æ—¶: {processing_time:.2f}ms")
                return None
        except Exception as e:
            tools.log(f"âŒ [DEBUG] æœç´¢å®ä½“å‡ºé”™: {str(e)}")
            import traceback
            tools.log(f"âŒ [DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return None
    
    def search_event(self, event_abstract: str) -> Optional[Dict[str, Any]]:
        """
        æœç´¢äº‹ä»¶ä¿¡æ¯
        
        Args:
            event_abstract: äº‹ä»¶æ‘˜è¦
            
        Returns:
            äº‹ä»¶è¯¦æƒ…å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        import time
        start_time = time.time()
        tools.log(f"ğŸ” [DEBUG] æœç´¢äº‹ä»¶ï¼Œæ‘˜è¦å¼€å¤´: '{event_abstract[:50]}...'")
        
        try:
            event_info = self.kg.get_event_info(event_abstract)
            processing_time = (time.time() - start_time) * 1000
            
            if event_info:
                result = {
                    "id": event_info["id"],
                    "abstract": event_info["abstract"],
                    "summary": event_info["event_summary"],
                    "time": event_info["first_seen"],
                    "sources": event_info["sources"],
                    "properties": event_info["properties"]
                }
                tools.log(f"âœ… [DEBUG] æ‰¾åˆ°äº‹ä»¶ï¼Œè€—æ—¶: {processing_time:.2f}msï¼Œäº‹ä»¶ID: {event_info['id']}")
                return result
            else:
                tools.log(f"âš ï¸ [DEBUG] æœªæ‰¾åˆ°äº‹ä»¶ï¼Œè€—æ—¶: {processing_time:.2f}ms")
                return None
        except Exception as e:
            tools.log(f"âŒ [DEBUG] æœç´¢äº‹ä»¶å‡ºé”™: {str(e)}")
            import traceback
            tools.log(f"âŒ [DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return None
    
    def get_entity_events(self, entity_name: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–å®ä½“å‚ä¸çš„äº‹ä»¶åˆ—è¡¨
        
        Args:
            entity_name: å®ä½“åç§°
            limit: è¿”å›äº‹ä»¶æ•°é‡é™åˆ¶
            
        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        import time
        start_time = time.time()
        tools.log(f"ğŸ” [DEBUG] è·å–å®ä½“äº‹ä»¶åˆ—è¡¨ï¼Œå®ä½“: '{entity_name}'ï¼Œé™åˆ¶: {limit}")
        
        try:
            # æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨
            if entity_name not in self.kg.entity_index:
                tools.log(f"âš ï¸ [DEBUG] å®ä½“ '{entity_name}' ä¸å­˜åœ¨äºç´¢å¼•ä¸­")
                return []
                
            events_data = self.kg.get_entity_events(entity_name)
            tools.log(f"ğŸ” [DEBUG] ä»çŸ¥è¯†å›¾è°±è·å–åˆ° {len(events_data)} ä¸ªäº‹ä»¶è®°å½•")
            
            result = []
            
            for i, event_item in enumerate(events_data):
                if i >= limit:
                    break
                
                event = event_item["event"]
                result.append({
                    "id": event["id"],
                    "abstract": event["abstract"],
                    "summary": event["event_summary"],
                    "time": event["first_seen"],
                    "source_count": len(event["sources"]),
                    "entity_count": event["properties"].get("entity_count", 0)
                })
            
            processing_time = (time.time() - start_time) * 1000
            tools.log(f"âœ… [DEBUG] è·å–å®ä½“äº‹ä»¶å®Œæˆï¼Œè¿”å› {len(result)} ä¸ªäº‹ä»¶ï¼Œè€—æ—¶: {processing_time:.2f}ms")
            return result
        except Exception as e:
            tools.log(f"âŒ [DEBUG] è·å–å®ä½“äº‹ä»¶å‡ºé”™: {str(e)}")
            import traceback
            tools.log(f"âŒ [DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return []
    
    def get_related_entities(self, entity_name: str, max_depth: int = 1, min_strength: float = 0.1) -> List[Dict[str, Any]]:
        """
        è·å–ä¸æŒ‡å®šå®ä½“ç›¸å…³çš„å…¶ä»–å®ä½“
        
        Args:
            entity_name: å®ä½“åç§°
            max_depth: å…³ç³»æœç´¢æ·±åº¦
            min_strength: æœ€å°å…³ç³»å¼ºåº¦
            
        Returns:
            ç›¸å…³å®ä½“åˆ—è¡¨
        """
        import time
        start_time = time.time()
        tools.log(f"ğŸ” [DEBUG] è·å–ç›¸å…³å®ä½“ï¼Œå®ä½“: '{entity_name}'ï¼Œæ·±åº¦: {max_depth}ï¼Œæœ€å°å¼ºåº¦: {min_strength}")
        
        try:
            # æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨
            if entity_name not in self.kg.entity_index:
                tools.log(f"âš ï¸ [DEBUG] å®ä½“ '{entity_name}' ä¸å­˜åœ¨äºç´¢å¼•ä¸­")
                return []
                
            related_data = self.kg.get_related_entities(entity_name, max_depth)
            tools.log(f"ğŸ” [DEBUG] ä»çŸ¥è¯†å›¾è°±è·å–åˆ° {len(related_data)} ç§å…³ç³»ç±»å‹")
            
            related_entities = []
            
            for rel_type, entities_list in related_data.items():
                tools.log(f"ğŸ” [DEBUG] å¤„ç†å…³ç³»ç±»å‹: '{rel_type}'ï¼Œå®ä½“åˆ—è¡¨é•¿åº¦: {len(entities_list)}")
                for item in entities_list:
                    relationship = item["relationship"]
                    strength = relationship["properties"].get("strength", 1.0)
                    
                    if strength >= min_strength:
                        related_entities.append({
                            "entity": {
                                "id": item["entity"]["id"],
                                "name": item["entity"]["name"],
                                "type": item["entity"]["properties"].get("entity_type", "entity")
                            },
                            "relationship": {
                                "type": rel_type,
                                "strength": strength,
                                "common_events": relationship["properties"].get("common_events", []),
                                "common_event_count": relationship["properties"].get("common_event_count", 0)
                            },
                            "depth": item["depth"]
                        })
            
            # æŒ‰å…³ç³»å¼ºåº¦æ’åº
            related_entities.sort(key=lambda x: x["relationship"]["strength"], reverse=True)
            
            processing_time = (time.time() - start_time) * 1000
            tools.log(f"âœ… [DEBUG] è·å–ç›¸å…³å®ä½“å®Œæˆï¼Œè¿”å› {len(related_entities)} ä¸ªç›¸å…³å®ä½“ï¼Œè€—æ—¶: {processing_time:.2f}ms")
            return related_entities
        except Exception as e:
            tools.log(f"âŒ [DEBUG] è·å–ç›¸å…³å®ä½“å‡ºé”™: {str(e)}")
            import traceback
            tools.log(f"âŒ [DEBUG] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return []
    
    def get_entity_path(self, start_entity: str, end_entity: str, max_depth: int = 3) -> Optional[List[Dict[str, Any]]]:
        """
        æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»è·¯å¾„
        
        Args:
            start_entity: èµ·å§‹å®ä½“åç§°
            end_entity: ç›®æ ‡å®ä½“åç§°
            max_depth: æœ€å¤§æœç´¢æ·±åº¦
            
        Returns:
            å…³ç³»è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨è·¯å¾„è¿”å›None
        """
        # æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨
        if start_entity not in self.kg.entity_index or end_entity not in self.kg.entity_index:
            return None
        
        start_id = self.kg.entity_index[start_entity]
        end_id = self.kg.entity_index[end_entity]
        
        # ç®€å•çš„BFSæœç´¢
        from collections import deque
        
        visited = {start_id: None}
        queue = deque([(start_id, 0)])
        found = False
        
        while queue and not found:
            current_id, depth = queue.popleft()
            
            if depth >= max_depth:
                continue
            
            for rel in self.kg.relationships:
                if rel["source"] == current_id and rel["target"] not in visited:
                    target_id = rel["target"]
                    visited[target_id] = (current_id, rel)
                    
                    if target_id == end_id:
                        found = True
                        break
                    
                    # åªæœç´¢å®ä½“èŠ‚ç‚¹
                    if self.kg.nodes[target_id]["type"] == "entity":
                        queue.append((target_id, depth + 1))
            
            if found:
                break
        
        # é‡æ„è·¯å¾„
        if not found:
            return None
        
        path = []
        current = end_id
        
        while visited[current]:
            prev_id, relationship = visited[current]
            path.append({
                "from": self.kg.nodes[prev_id],
                "to": self.kg.nodes[current],
                "relationship": relationship
            })
            current = prev_id
        
        # åè½¬è·¯å¾„ï¼Œä½¿å…¶ä»èµ·å§‹å®ä½“åˆ°ç›®æ ‡å®ä½“
        path.reverse()
        return path
    
    def get_graph_summary(self) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†å›¾è°±æ‘˜è¦ä¿¡æ¯
        
        Returns:
            çŸ¥è¯†å›¾è°±æ‘˜è¦ç»Ÿè®¡
        """
        stats = self.kg.get_graph_statistics()
        
        return {
            "total_nodes": stats["total_nodes"],
            "total_relationships": stats["total_relationships"],
            "entity_count": stats["entity_count"],
            "event_count": stats["event_count"],
            "entity_types": stats["entity_types"],
            "relationship_types": stats["relationship_types"],
            "last_updated": stats["last_updated"]
        }
    
    def refresh_graph(self, force: bool = False) -> bool:
        """
        åˆ·æ–°çŸ¥è¯†å›¾è°±ï¼ˆé‡æ–°æ„å»ºï¼‰
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            æ˜¯å¦åˆ·æ–°æˆåŠŸ
        """
        try:
            build_knowledge_graph()
            self.kg = get_knowledge_graph()  # é‡æ–°è·å–å®ä¾‹
            return True
        except Exception as e:
            tools.log(f"âŒ åˆ·æ–°çŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
            return False
    
    def export_graph_data(self, output_path: Optional[str] = None) -> bool:
        """
        å¯¼å‡ºçŸ¥è¯†å›¾è°±æ•°æ®
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            path = Path(output_path) if output_path else tools.DATA_DIR / "kg_export.json"
            self.kg.save_graph(path)
            return True
        except Exception as e:
            tools.log(f"âŒ å¯¼å‡ºçŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
            return False
    
    def search_entities_by_type(self, entity_type: str) -> List[Dict[str, Any]]:
        """
        æŒ‰ç±»å‹æœç´¢å®ä½“
        
        Args:
            entity_type: å®ä½“ç±»å‹
            
        Returns:
            å®ä½“åˆ—è¡¨
        """
        entities = []
        
        for node in self.kg.nodes.values():
            if node["type"] == "entity" and node["properties"].get("entity_type") == entity_type:
                entities.append({
                    "id": node["id"],
                    "name": node["name"],
                    "first_seen": node["first_seen"],
                    "sources": node["sources"]
                })
        
        return entities
    
    def get_events_by_time_range(self, start_time: str = "", end_time: str = "") -> List[Dict[str, Any]]:
        """
        æŒ‰æ—¶é—´èŒƒå›´è·å–äº‹ä»¶
        
        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
            
        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        events = []
        
        for node in self.kg.nodes.values():
            if node["type"] == "event":
                event_time = node["first_seen"]
                
                if start_time and event_time < start_time:
                    continue
                if end_time and event_time > end_time:
                    continue
                
                events.append({
                    "id": node["id"],
                    "abstract": node["abstract"],
                    "summary": node["event_summary"],
                    "time": event_time,
                    "entity_count": node["properties"].get("entity_count", 0)
                })
        
        # æŒ‰æ—¶é—´æ’åº
        events.sort(key=lambda x: x["time"], reverse=True)
        return events
    
    def get_top_related_entities(self, entity_name: str, top_n: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–ä¸æŒ‡å®šå®ä½“æœ€ç›¸å…³çš„å®ä½“ï¼ˆæŒ‰å…±åŒäº‹ä»¶æ•°æ’åºï¼‰
        
        Args:
            entity_name: å®ä½“åç§°
            top_n: è¿”å›æ•°é‡
            
        Returns:
            æœ€ç›¸å…³å®ä½“åˆ—è¡¨
        """
        related_entities = self.get_related_entities(entity_name, max_depth=2)
        
        # æŒ‰å…±åŒäº‹ä»¶æ•°æ’åº
        related_entities.sort(key=lambda x: x["relationship"].get("common_event_count", 0), reverse=True)
        
        # æˆªå–å‰top_nä¸ª
        return related_entities[:top_n]
    
    def get_knowledge_graph_insights(self, entity_name: str) -> Dict[str, Any]:
        """
        è·å–å…³äºå®ä½“çš„çŸ¥è¯†å›¾è°±æ´å¯Ÿ
        
        Args:
            entity_name: å®ä½“åç§°
            
        Returns:
            æ´å¯Ÿç»“æœå­—å…¸
        """
        if entity_name not in self.kg.entity_index:
            return {"error": "å®ä½“ä¸å­˜åœ¨"}
        
        # è·å–å®ä½“åŸºæœ¬ä¿¡æ¯
        entity_info = self.search_entity(entity_name)
        
        # è·å–å®ä½“å‚ä¸çš„äº‹ä»¶
        events = self.get_entity_events(entity_name, limit=5)
        
        # è·å–ç›¸å…³å®ä½“
        related_entities = self.get_top_related_entities(entity_name, top_n=5)
        
        # è®¡ç®—å‚ä¸äº‹ä»¶ç»Ÿè®¡
        event_stats = {
            "total_events": len(self.get_entity_events(entity_name, limit=1000)),
            "recent_events": len(events),
            "event_categories": self._categorize_events(events)
        }
        
        # è®¡ç®—ç›¸å…³å®ä½“ç»Ÿè®¡
        entity_stats = {
            "related_entity_count": len(self.get_related_entities(entity_name)),
            "top_related_entities": related_entities,
            "entity_type_distribution": self._calculate_related_type_distribution(related_entities)
        }
        
        return {
            "entity": entity_info,
            "event_statistics": event_stats,
            "relationship_statistics": entity_stats,
            "insights": self._generate_entity_insights(entity_info, event_stats, entity_stats)
        }
    
    def _categorize_events(self, events: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        å¯¹äº‹ä»¶è¿›è¡Œç®€å•åˆ†ç±»
        
        Args:
            events: äº‹ä»¶åˆ—è¡¨
            
        Returns:
            åˆ†ç±»ç»Ÿè®¡
        """
        categories = {
            "æ”¿æ²»": 0,
            "ç»æµ": 0,
            "ç¤¾ä¼š": 0,
            "å…¶ä»–": 0
        }
        
        # ç®€å•çš„å…³é”®è¯åˆ†ç±»
        for event in events:
            summary = event.get("summary", "") + " " + event.get("abstract", "")
            
            if any(keyword in summary for keyword in ["æ”¿åºœ", "æ”¿ç­–", "é€‰ä¸¾", "å®˜å‘˜", "ä¼šè®®", "æ³•æ¡ˆ"]):
                categories["æ”¿æ²»"] += 1
            elif any(keyword in summary for keyword in ["ç»æµ", "æŠ•èµ„", "å¸‚åœº", "ä»·æ ¼", "è´¸æ˜“", "ä¼ä¸š"]):
                categories["ç»æµ"] += 1
            elif any(keyword in summary for keyword in ["ç¤¾ä¼š", "æ°‘ç”Ÿ", "æ•™è‚²", "åŒ»ç–—", "ç¯å¢ƒ", "ç§‘æŠ€"]):
                categories["ç¤¾ä¼š"] += 1
            else:
                categories["å…¶ä»–"] += 1
        
        return categories
    
    def _calculate_related_type_distribution(self, related_entities: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        è®¡ç®—ç›¸å…³å®ä½“ç±»å‹åˆ†å¸ƒ
        
        Args:
            related_entities: ç›¸å…³å®ä½“åˆ—è¡¨
            
        Returns:
            ç±»å‹åˆ†å¸ƒç»Ÿè®¡
        """
        distribution = {}
        
        for item in related_entities:
            entity_type = item["entity"].get("type", "entity")
            distribution[entity_type] = distribution.get(entity_type, 0) + 1
        
        return distribution
    
    def _generate_entity_insights(self, entity_info: Dict[str, Any], 
                               event_stats: Dict[str, Any], 
                               relationship_stats: Dict[str, Any]) -> List[str]:
        """
        ç”Ÿæˆå®ä½“æ´å¯Ÿ
        
        Args:
            entity_info: å®ä½“ä¿¡æ¯
            event_stats: äº‹ä»¶ç»Ÿè®¡
            relationship_stats: å…³ç³»ç»Ÿè®¡
            
        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        insights = []
        
        # æ ¹æ®ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆæ´å¯Ÿ
        if event_stats["total_events"] > 10:
            insights.append(f"{entity_info['name']}åœ¨çŸ¥è¯†å›¾è°±ä¸­å‚ä¸äº†{event_stats['total_events']}ä¸ªäº‹ä»¶ï¼Œæ´»è·ƒåº¦è¾ƒé«˜ã€‚")
        
        # åˆ†æäº‹ä»¶ç±»åˆ«
        categories = event_stats["event_categories"]
        max_category = max(categories, key=categories.get)
        if categories[max_category] / sum(categories.values()) > 0.5:
            insights.append(f"{entity_info['name']}çš„æ´»åŠ¨ä¸»è¦é›†ä¸­åœ¨{max_category}é¢†åŸŸã€‚")
        
        # åˆ†æç›¸å…³å®ä½“
        if relationship_stats["related_entity_count"] > 20:
            insights.append(f"{entity_info['name']}ä¸{relationship_stats['related_entity_count']}ä¸ªå…¶ä»–å®ä½“å­˜åœ¨å…³è”ï¼Œç½‘ç»œå½±å“åŠ›è¾ƒå¤§ã€‚")
        
        # åˆ†æå®ä½“ç±»å‹
        if entity_info["type"] == "person":
            insights.append(f"{entity_info['name']}æ˜¯ä¸€ä¸ªäººç‰©å®ä½“ï¼Œå¯èƒ½åœ¨å¤šä¸ªäº‹ä»¶ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚")
        elif entity_info["type"] == "organization":
            insights.append(f"{entity_info['name']}æ˜¯ä¸€ä¸ªç»„ç»‡å®ä½“ï¼Œå¯èƒ½æ¶‰åŠå¤šæ–¹é¢çš„æ´»åŠ¨å’Œå…³ç³»ã€‚")
        
        return insights

# å…¨å±€æ¥å£å®ä¾‹
KG_INTERFACE = None

def get_kg_interface() -> KnowledgeGraphInterface:
    """
    è·å–çŸ¥è¯†å›¾è°±æ¥å£å•ä¾‹
    
    Returns:
        KnowledgeGraphInterfaceå®ä¾‹
    """
    global KG_INTERFACE
    tools.log(f"ğŸ” [DEBUG] è·å–çŸ¥è¯†å›¾è°±æ¥å£å•ä¾‹ï¼Œå½“å‰çŠ¶æ€: {'å·²å­˜åœ¨' if KG_INTERFACE else 'ä¸å­˜åœ¨'}")
    if KG_INTERFACE is None:
        tools.log(f"ğŸ” [DEBUG] åˆ›å»ºæ–°çš„çŸ¥è¯†å›¾è°±æ¥å£å®ä¾‹")
        KG_INTERFACE = KnowledgeGraphInterface()
        tools.log(f"âœ… [DEBUG] çŸ¥è¯†å›¾è°±æ¥å£å®ä¾‹åˆ›å»ºå®Œæˆ")
    else:
        tools.log(f"âœ… [DEBUG] å¤ç”¨å·²å­˜åœ¨çš„çŸ¥è¯†å›¾è°±æ¥å£å®ä¾‹")
    return KG_INTERFACE

# ä¾¿æ·å‡½æ•°
def search_entity(entity_name: str) -> Optional[Dict[str, Any]]:
    """æœç´¢å®ä½“ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° search_entity: '{entity_name}'")
    return get_kg_interface().search_entity(entity_name)

def get_entity_events(entity_name: str, limit: int = 10) -> List[Dict[str, Any]]:
    """è·å–å®ä½“äº‹ä»¶çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° get_entity_events: '{entity_name}'ï¼Œé™åˆ¶: {limit}")
    return get_kg_interface().get_entity_events(entity_name, limit)

def get_related_entities(entity_name: str, max_depth: int = 1) -> List[Dict[str, Any]]:
    """è·å–ç›¸å…³å®ä½“çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° get_related_entities: '{entity_name}'ï¼Œæ·±åº¦: {max_depth}")
    return get_kg_interface().get_related_entities(entity_name, max_depth)

def get_graph_summary() -> Dict[str, Any]:
    """è·å–çŸ¥è¯†å›¾è°±æ‘˜è¦çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° get_graph_summary")
    return get_kg_interface().get_graph_summary()

def refresh_graph(force: bool = False) -> bool:
    """åˆ·æ–°çŸ¥è¯†å›¾è°±çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° refresh_graphï¼Œå¼ºåˆ¶åˆ·æ–°: {force}")
    return get_kg_interface().refresh_graph(force)

def get_entity_insights(entity_name: str) -> Dict[str, Any]:
    """è·å–å®ä½“æ´å¯Ÿçš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° get_entity_insights: '{entity_name}'")
    return get_kg_interface().get_knowledge_graph_insights(entity_name)

def search_entities(keyword: str) -> List[Dict[str, Any]]:
    """æœç´¢å®ä½“çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° search_entities: '{keyword}'")
    return get_kg_interface().kg.search_entities(keyword)

def search_events(keyword: str) -> List[Dict[str, Any]]:
    """æœç´¢äº‹ä»¶çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° search_events: '{keyword}'")
    return get_kg_interface().kg.search_events(keyword)

def get_entity_relations(entity_name: str) -> List[Dict[str, Any]]:
    """è·å–å®ä½“å…³ç³»çš„ä¾¿æ·å‡½æ•°"""
    tools.log(f"ğŸ” [DEBUG] è°ƒç”¨ä¾¿æ·å‡½æ•° get_entity_relations: '{entity_name}'")
    return get_kg_interface().kg.get_entity_relationships(entity_name)

if __name__ == "__main__":
    # æµ‹è¯•æ¥å£åŠŸèƒ½
    interface = get_kg_interface()
    print("çŸ¥è¯†å›¾è°±æ‘˜è¦:")
    print(json.dumps(get_graph_summary(), ensure_ascii=False, indent=2))
