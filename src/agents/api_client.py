import random
import json
import os
import time
from ..utils.tool_function import tools
tools=tools()
from typing import Optional, Dict, Any, List
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
from ..core import ConfigManager, get_key_manager
class LLMAPIPool:
    def __init__(self):
        PROJECT_ROOT = Path(__file__).parent.parent.parent.resolve()
        dotenv_path = PROJECT_ROOT / "config" / ".env.local"
        load_dotenv(dotenv_path)
        self.clients = []
        self._load_clients()
        if not self.clients:
            raise ValueError("[LLMè¯·æ±‚] âŒ æœªé…ç½®ä»»ä½•æœ‰æ•ˆçš„ LLM API")

    def _load_clients(self):
        """ä»å®‰å…¨çš„å¯†é’¥ç®¡ç†å™¨åŠ è½½APIå®¢æˆ·ç«¯"""
        try:
            key_manager = get_key_manager()

            # è·å–é…ç½®ç®¡ç†å™¨æ¥è·å–æœåŠ¡åˆ—è¡¨å’Œæ¨¡å‹ä¿¡æ¯
            config_manager = ConfigManager()

            # é¦–å…ˆå°è¯•ä»é…ç½®è·å–æœåŠ¡åˆ—è¡¨ï¼ˆä¸åŒ…å«å¯†é’¥ï¼‰
            services_config = config_manager.get_config_value("llm_services", None, "agent1_config")

            if not services_config:
                # å¦‚æœæ²¡æœ‰é…ç½®æœåŠ¡åˆ—è¡¨ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆå‘åå…¼å®¹ï¼‰
                legacy_config = os.getenv("AGENT1_LLM_APIS")
                if legacy_config:
                    try:
                        legacy_apis = json.loads(legacy_config)
                        services_config = []
                        for cfg in legacy_apis:
                            if cfg.get("enabled", True):
                                # å°†æ—§é…ç½®è¿ç§»åˆ°æ–°ç³»ç»Ÿ
                                service_name = f"llm_{cfg['name'].lower()}"
                                api_key = cfg["api_key"]
                                metadata = {
                                    "base_url": cfg["base_url"],
                                    "model": cfg["model"],
                                    "enabled": True
                                }
                                key_manager.store_api_key(service_name, api_key, metadata)
                                services_config.append({
                                    "name": cfg["name"],
                                    "service_key": service_name
                                })
                        tools.log("[LLMè¯·æ±‚] âœ… å·²è¿ç§»æ—§é…ç½®åˆ°å®‰å…¨å­˜å‚¨")
                    except Exception as e:
                        tools.log(f"[LLMè¯·æ±‚] âš ï¸ è¿ç§»æ—§é…ç½®å¤±è´¥: {e}")

            if not services_config:
                tools.log("[LLMè¯·æ±‚] âŒ æœªæ‰¾åˆ° LLM æœåŠ¡é…ç½®")
                return

            # ä»å®‰å…¨çš„å¯†é’¥ç®¡ç†å™¨åŠ è½½æ¯ä¸ªæœåŠ¡
            for service in services_config:
                service_name = service["name"]
                service_key = service.get("service_key", f"llm_{service_name.lower()}")

                try:
                    # ä»å¯†é’¥ç®¡ç†å™¨è·å–APIå¯†é’¥
                    api_key = key_manager.get_api_key(service_key)
                    if not api_key:
                        tools.log(f"[LLMè¯·æ±‚] âš ï¸ æœªæ‰¾åˆ°æœåŠ¡ {service_name} çš„APIå¯†é’¥")
                        continue

                    # è·å–æœåŠ¡å…ƒæ•°æ®
                    key_info = key_manager.get_key_info(service_key)
                    if not key_info:
                        tools.log(f"[LLMè¯·æ±‚] âš ï¸ æœªæ‰¾åˆ°æœåŠ¡ {service_name} çš„å…ƒæ•°æ®")
                        continue

                    metadata = key_info.get("metadata", {})
                    base_url = metadata.get("base_url")
                    model = metadata.get("model")

                    # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
                    client = OpenAI(
                        api_key=api_key,
                        base_url=base_url
                    )

                    self.clients.append({
                        "name": service_name,
                        "client": client,
                        "model": model,
                        "service_key": service_key
                    })

                    tools.log(f"[LLMè¯·æ±‚] âœ… å·²åŠ è½½æœåŠ¡ {service_name} (æ¨¡å‹: {model})")

                except Exception as e:
                    tools.log(f"[LLMè¯·æ±‚] âš ï¸ åŠ è½½æœåŠ¡ {service_name} å¤±è´¥: {e}")

        except Exception as e:
            tools.log(f"[LLMè¯·æ±‚] âŒ åˆå§‹åŒ–APIå®¢æˆ·ç«¯å¤±è´¥: {e}")

    def add_service(self, name: str, api_key: str, base_url: str,
                   model: str, enabled: bool = True) -> bool:
        """
        æ·»åŠ æ–°çš„LLMæœåŠ¡

        Args:
            name: æœåŠ¡æ˜¾ç¤ºåç§°
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            enabled: æ˜¯å¦å¯ç”¨

        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            key_manager = get_key_manager()
            service_key = f"llm_{name.lower()}"

            metadata = {
                "base_url": base_url,
                "model": model,
                "enabled": enabled,
                "type": "llm"
            }

            key_manager.store_api_key(service_key, api_key, metadata)

            # é‡æ–°åŠ è½½å®¢æˆ·ç«¯
            self.clients = []
            self._load_clients()

            tools.log(f"[LLMè¯·æ±‚] âœ… å·²æ·»åŠ æœåŠ¡ {name}")
            return True

        except Exception as e:
            tools.log(f"[LLMè¯·æ±‚] âŒ æ·»åŠ æœåŠ¡ {name} å¤±è´¥: {e}")
            return False

    def remove_service(self, name: str) -> bool:
        """
        ç§»é™¤LLMæœåŠ¡

        Args:
            name: æœåŠ¡åç§°

        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        try:
            key_manager = get_key_manager()
            service_key = f"llm_{name.lower()}"

            if key_manager.delete_api_key(service_key):
                # é‡æ–°åŠ è½½å®¢æˆ·ç«¯
                self.clients = []
                self._load_clients()
                tools.log(f"[LLMè¯·æ±‚] âœ… å·²ç§»é™¤æœåŠ¡ {name}")
                return True
            else:
                tools.log(f"[LLMè¯·æ±‚] âš ï¸ æœåŠ¡ {name} ä¸å­˜åœ¨")
                return False

        except Exception as e:
            tools.log(f"[LLMè¯·æ±‚] âŒ ç§»é™¤æœåŠ¡ {name} å¤±è´¥: {e}")
            return False

    def list_services(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰LLMæœåŠ¡ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰

        Returns:
            æœåŠ¡ä¿¡æ¯åˆ—è¡¨
        """
        services = []
        key_manager = get_key_manager()

        for client in self.clients:
            service_key = client["service_key"]
            key_info = key_manager.get_key_info(service_key)

            if key_info:
                services.append({
                    "name": client["name"],
                    "model": client["model"],
                    "base_url": key_info["metadata"].get("base_url"),
                    "enabled": key_info["metadata"].get("enabled", True),
                    "created_at": key_info.get("created_at"),
                    "last_used": key_info.get("last_used")
                })

        return services

    def call(self, prompt: str, max_tokens: int = 1500, timeout: int = 55, retries: int = 2) -> Optional[str]:
        """
        å°è¯•è°ƒç”¨ API æ± ä¸­çš„æœåŠ¡ï¼Œç›´åˆ°æˆåŠŸæˆ–è€—å°½é‡è¯•æ¬¡æ•°ã€‚
        è¿”å› raw LLM content (str)ï¼Œç”±è°ƒç”¨æ–¹è§£æ JSONã€‚
        """
        available = self.clients.copy()
        if not available:
            return None

        for attempt in range(retries + 1):
            if not available:
                available = self.clients.copy()  # é‡ç½®å€™é€‰æ± 

            # éšæœºé€‰ä¸€ä¸ªï¼ˆç®€å•è´Ÿè½½å‡è¡¡ï¼‰ï¼Œä¹Ÿå¯æ”¹ä¸º round-robin
            choice = random.choice(available)
            name, client, model = choice["name"], choice["client"], choice["model"]

            try:
                tools.log(f"[LLMè¯·æ±‚] å°è¯• API [{name}] (ç¬¬ {attempt+1} æ¬¡)")
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=max_tokens,
                    timeout=timeout,
                    stream=False
                )
                content = response.choices[0].message.content.strip()
                tools.log(f"[LLMè¯·æ±‚] âœ… API [{name}] æˆåŠŸè¿”å›")
                return content

            except Exception as e:
                tools.log(f"[LLMè¯·æ±‚] âŒ API [{name}] å¤±è´¥: {e}")
                available.remove(choice)  # ä¸´æ—¶å‰”é™¤æ•…éšœèŠ‚ç‚¹
                if attempt < retries and len(available) == 0:
                    available = self.clients.copy()  # æ— å¯ç”¨æ—¶é‡æ–°å¯ç”¨æ‰€æœ‰

            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

        tools.log("[LLMè¯·æ±‚] ğŸ’¥ æ‰€æœ‰ API å°è¯•å‡å¤±è´¥")
        return None