# src/data/news_collector.py
import aiohttp
import asyncio
import pandas as pd
from datetime import datetime, timedelta, timezone
import time
from typing import Dict, List, Optional, Any
import json
from enum import Enum
import os
os.environ['AIODNS_NO_winloop'] = '1'
import sys
if sys.platform == 'win32':
   asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
import aiodns
loop = asyncio.get_event_loop()
resolver = aiodns.DNSResolver(loop=loop)

def _json_serializer(obj):
    """æ”¯æŒ datetime çš„ JSON åºåˆ—åŒ–è¾…åŠ©å‡½æ•°"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")

class NewsType(Enum):
    """æ–°é—»ç±»å‹æšä¸¾"""
    FLASH = "flash"  # å¿«è®¯
    ARTICLE = "article"  # æ–‡ç« 
    IMPORTANT = "push"  # é‡è¦æ–°é—»

class Language(Enum):
    """è¯­è¨€ç±»å‹æšä¸¾"""
    CN = "cn"  # ä¸­æ–‡
    EN = "en"  # è‹±æ–‡
    CHT = "cht"  # ç¹ä½“ä¸­æ–‡

class BlockbeatsNewsCollector:
    """Blockbeatsæ–°é—»æ•°æ®æ”¶é›†å™¨"""
    
    BASE_URL = "https://api.theblockbeats.news/v1/"
    
    def __init__(self, language: Language = Language.CN, timeout: int = 30):
        """
        åˆå§‹åŒ–æ–°é—»æ”¶é›†å™¨
        
            language: è¯­è¨€ç±»å‹
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.language = language
        self.timeout = timeout
        self.session = None
        self.cache = {}  # ç®€å•çš„å†…å­˜ç¼“å­˜
        self.cache_ttl = 300  # ç¼“å­˜æœ‰æ•ˆæœŸ5åˆ†é’Ÿ
        self._connector = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        if not self.session:
            self._connector = aiohttp.TCPConnector(limit=10)
            self.session = aiohttp.ClientSession(
                connector=self._connector,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.session.close()
    
    async def close(self):
        """æ˜¾å¼å…³é—­è¿æ¥"""
        if self.session:
            await self.session.close()
            self.session = None
        if self._connector:
            await self._connector.close()
            self._connector = None

    async def ensure_session(self):
        """ç¡®ä¿ä¼šè¯å­˜åœ¨"""
        if not self.session:
            self._connector = aiohttp.TCPConnector(limit=10)
            self.session = aiohttp.ClientSession(
                connector=self._connector,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            )

    def _get_cache_key(self, endpoint: str, params: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{endpoint}:{json.dumps(params, sort_keys=True)}"
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key in self.cache:
            cached_time, _ = self.cache[cache_key]
            return (time.time() - cached_time) < self.cache_ttl
        return False
    
    async def _make_request(self, endpoint: str, params: Dict) -> Dict[str, Any]:
        """å‘é€APIè¯·æ±‚"""
        await self.ensure_session()  # ç¡®ä¿ä¼šè¯å­˜åœ¨

        cache_key = self._get_cache_key(endpoint, params)
        
        # æ£€æŸ¥ç¼“å­˜
        if self._is_cache_valid(cache_key):
            _, cached_data = self.cache[cache_key]
            print(f"ğŸ“° ä½¿ç”¨ç¼“å­˜æ•°æ®: {endpoint}")
            return cached_data
        
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        url = f"{self.BASE_URL}{endpoint}"
        
        try:
            async with self.session.get(url, params=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                
                result = await response.json()
                
                # ç¼“å­˜ç»“æœ
                self.cache[cache_key] = (time.time(), result)
                
                return result
                
        except aiohttp.ClientError as e:
            raise Exception(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
        except json.JSONDecodeError as e:
            raise Exception(f"JSONè§£æé”™è¯¯: {str(e)}")
    
    async def get_flash_news(self, 
                           page: int = 1, 
                           size: int = 10,
                           news_type: NewsType = NewsType.IMPORTANT) -> List[Dict]:
        """
        è·å–å¿«è®¯æ–°é—»
        
        Args:
            page: é¡µç 
            size: æ¯é¡µæ•°é‡
            news_type: æ–°é—»ç±»å‹
            
        Returns:
            å¿«è®¯æ–°é—»åˆ—è¡¨
        """
        endpoint = "open-api/open-flash"
        params = {
            "page": page,
            "size": size,
            "type": news_type.value,
            "lang": self.language.value
        }
        
        try:
            result = await self._make_request(endpoint, params)
            
            if result.get("status") == 0:
                data = result.get("data", {})
                news_list = data.get("data", [])
                
                # å¤„ç†æ—¶é—´æˆ³
                for news in news_list:
                    news = self._process_news_timestamp(news)
                
                print(f"âœ… è·å–åˆ° {len(news_list)} æ¡å¿«è®¯æ–°é—»")
                return news_list
            else:
                error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                raise Exception(f"APIè¿”å›é”™è¯¯: {error_msg}")
                
        except Exception as e:
            print(f"âŒ è·å–å¿«è®¯æ–°é—»å¤±è´¥: {str(e)}")
            return []
    
    async def get_articles(self, 
                         page: int = 1, 
                         size: int = 10,
                         news_type: NewsType = NewsType.IMPORTANT) -> List[Dict]:
        """
        è·å–æ–‡ç« 
        
        Args:
            page: é¡µç 
            size: æ¯é¡µæ•°é‡
            news_type: æ–°é—»ç±»å‹
            
        Returns:
            æ–‡ç« åˆ—è¡¨
        """
        endpoint = "open-api/open-information"
        params = {
            "page": page,
            "size": size,
            "type": news_type.value,
            "lang": self.language.value
        }
        
        try:
            result = await self._make_request(endpoint, params)
            
            if result.get("status") == 0:
                data = result.get("data", {})
                articles = data.get("data", [])
                
                # å¤„ç†æ—¶é—´æˆ³
                for article in articles:
                    article = self._process_news_timestamp(article)
                
                print(f"âœ… è·å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                return articles
            else:
                error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                raise Exception(f"APIè¿”å›é”™è¯¯: {error_msg}")
                
        except Exception as e:
            print(f"âŒ è·å–æ–‡ç« å¤±è´¥: {str(e)}")
            return []
    
    def _process_news_timestamp(self, news_item: Dict) -> Dict:
        """å¤„ç†æ–°é—»æ—¶é—´æˆ³"""
        create_time = news_item.get("create_time")
        if create_time:
            try:
                # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetimeå¯¹è±¡
                timestamp = int(create_time)
                dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
                news_item["datetime"] = dt
                news_item["formatted_time"] = dt.strftime("%Y-%m-%d %H:%M:%S")
            except (ValueError, TypeError):
                news_item["datetime"] = None
                news_item["formatted_time"] = "æœªçŸ¥æ—¶é—´"
        
        return news_item
    
    async def get_latest_important_news(self, limit: int = 20) -> List[Dict]:
        """
        è·å–æœ€æ–°çš„é‡è¦æ–°é—»ï¼ˆå¿«è®¯+æ–‡ç« ï¼‰
        
        Args:
            limit: æ€»æ•°é‡é™åˆ¶
            
        Returns:
            åˆå¹¶çš„é‡è¦æ–°é—»åˆ—è¡¨
        """
        # è·å–å¿«è®¯å’Œæ–‡ç« 
        flash_news = await self.get_flash_news(page=1, size=limit//2, news_type=NewsType.IMPORTANT)
        articles = await self.get_articles(page=1, size=limit//2, news_type=NewsType.IMPORTANT)
        
        # åˆå¹¶å¹¶æ’åº
        all_news = flash_news + articles
        all_news.sort(key=lambda x: x.get("datetime") or datetime.min.replace(tzinfo=timezone.utc), reverse=True)
        
        # é™åˆ¶æ•°é‡
        return all_news[:limit]
    
    async def search_news_by_keyword(self, 
                                   keyword: str, 
                                   news_type: NewsType = None,
                                   limit: int = 50) -> List[Dict]:
        """
        æ ¹æ®å…³é”®è¯æœç´¢æ–°é—»ï¼ˆé€šè¿‡è·å–å¤šé¡µæ•°æ®å®ç°ç®€å•æœç´¢ï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            news_type: æ–°é—»ç±»å‹ï¼ŒNoneè¡¨ç¤ºæœç´¢æ‰€æœ‰ç±»å‹
            limit: æœ€å¤§ç»“æœæ•°é‡
            
        Returns:
            åŒ…å«å…³é”®è¯çš„æ–°é—»åˆ—è¡¨
        """
        all_results = []
        page = 1
        page_size = 20
        
        while len(all_results) < limit:
            try:
                # è·å–å¿«è®¯
                if news_type is None or news_type == NewsType.FLASH:
                    flash_news = await self.get_flash_news(page=page, size=page_size)
                    all_results.extend(flash_news)
                
                # è·å–æ–‡ç« 
                if news_type is None or news_type == NewsType.ARTICLE:
                    articles = await self.get_articles(page=page, size=page_size)
                    all_results.extend(articles)
                
                # å¦‚æœæ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œåœæ­¢æœç´¢
                if not flash_news and not articles:
                    break
                
                page += 1
                # é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.5)
                
            except Exception as e:
                print(f"âŒ æœç´¢æ–°é—»æ—¶å‡ºé”™: {str(e)}")
                break
        
        # è¿‡æ»¤åŒ…å«å…³é”®è¯çš„æ–°é—»
        filtered_results = []
        for news in all_results:
            title = news.get("title", "").lower()
            content = news.get("content", "").lower()
            description = news.get("description", "").lower()
            
            if (keyword.lower() in title or 
                keyword.lower() in content or 
                keyword.lower() in description):
                filtered_results.append(news)
        
        # æŒ‰æ—¶é—´æ’åº
        filtered_results.sort(key=lambda x: x.get("datetime") or datetime.min.replace(tzinfo=timezone.utc), reverse=True)
        
        return filtered_results[:limit]
    
    def news_to_dataframe(self, news_list: List[Dict]) -> pd.DataFrame:
        """
        å°†æ–°é—»åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            DataFrameæ ¼å¼çš„æ–°é—»æ•°æ®
        """
        if not news_list:
            return pd.DataFrame()
        
        # æå–å…³é”®å­—æ®µ
        processed_news = []
        for news in news_list:
            processed_news.append({
                "id": news.get("id"),
                "title": news.get("title", ""),
                "content": news.get("content", news.get("description", "")),
                "type": "flash" if "content" in news else "article",
                "link": news.get("link", ""),
                "image_url": news.get("pic", ""),
                "create_time": news.get("formatted_time", ""),
                "timestamp": news.get("datetime"),
                "is_original": news.get("is_original", False),
                "column": news.get("column", ""),
                # === æ–°å¢å­—æ®µï¼šç”¨äºçŸ¥è¯†å›¾è°±æ„å»º ===
                "entities": [],          # é¢„ç•™ï¼šç”±æ™ºèƒ½ä½“1å¡«å……å®ä½“åˆ—è¡¨ï¼Œå¦‚ ["BTC", "ä»¥å¤ªåŠ"]
                "event_type": None,      # é¢„ç•™ï¼šäº‹ä»¶ç±»å‹ï¼Œå¦‚ "regulation", "hack"
                "raw_json": json.dumps(news, default=_json_serializer, ensure_ascii=False)  # é¢„ç•™ï¼šåŸå§‹æ•°æ®å›æº¯
            })
        
        df = pd.DataFrame(processed_news)
        if not df.empty and "timestamp" in df.columns:
            df = df.sort_values("timestamp", ascending=False)
            df = df.reset_index(drop=True)
        
        return df
    
    async def get_news_summary(self, hours: int = 24) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ–°é—»æ‘˜è¦
        
        Args:
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            
        Returns:
            æ–°é—»æ‘˜è¦ç»Ÿè®¡
        """
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=hours)
        
        # è·å–æœ€è¿‘çš„é‡è¦æ–°é—»
        all_news = await self.get_latest_important_news(limit=100)
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ–°é—»
        recent_news = []
        for news in all_news:
            news_time = news.get("datetime")
            if news_time and start_time <= news_time <= end_time:
                recent_news.append(news)
        
        # ç»Ÿè®¡ä¿¡æ¯
        flash_count = sum(1 for news in recent_news if "content" in news)
        article_count = len(recent_news) - flash_count
        
        # æå–çƒ­é—¨å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
        all_titles = " ".join([news.get("title", "") for news in recent_news])
        words = all_titles.split()
        from collections import Counter
        word_freq = Counter(words)
        top_keywords = [word for word, count in word_freq.most_common(10) if len(word) > 1]
        
        return {
            "total_news": len(recent_news),
            "flash_count": flash_count,
            "article_count": article_count,
            "time_range": f"æœ€è¿‘{hours}å°æ—¶",
            "top_keywords": top_keywords[:5],
            "latest_news": recent_news[:10]  # æœ€æ–°10æ¡æ–°é—»
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        print("âœ… æ–°é—»ç¼“å­˜å·²æ¸…ç©º")


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
async def news_collector_demo():
    """æ–°é—»æ”¶é›†å™¨ä½¿ç”¨ç¤ºä¾‹"""
    
    async with BlockbeatsNewsCollector(language=Language.CN) as collector:
        print("ğŸš€ Blockbeatsæ–°é—»æ”¶é›†å™¨æ¼”ç¤º")
        print("=" * 50)
        
        # 1. è·å–å¿«è®¯æ–°é—»
        print("\n1. è·å–é‡è¦å¿«è®¯:")
        flash_news = await collector.get_flash_news(page=1, size=5, news_type=NewsType.IMPORTANT)
        for i, news in enumerate(flash_news, 1):
            print(f"   {i}. {news.get('title')} [{news.get('formatted_time')}]")
        
        # 2. è·å–æ–‡ç« 
        print("\n2. è·å–é‡è¦æ–‡ç« :")
        articles = await collector.get_articles(page=1, size=3, news_type=NewsType.IMPORTANT)
        for i, article in enumerate(articles, 1):
            print(f"   {i}. {article.get('title')} [{article.get('formatted_time')}]")
        
        # 3. è·å–æœ€æ–°é‡è¦æ–°é—»
        print("\n3. æœ€æ–°é‡è¦æ–°é—»:")
        important_news = await collector.get_latest_important_news(limit=5)
        for i, news in enumerate(important_news, 1):
            news_type = "å¿«è®¯" if "content" in news else "æ–‡ç« "
            print(f"   {i}. [{news_type}] {news.get('title')}")
        
        # 4. æœç´¢æ–°é—»
        print("\n4. æœç´¢'BTC'ç›¸å…³æ–°é—»:")
        btc_news = await collector.search_news_by_keyword("BTC", limit=3)
        for i, news in enumerate(btc_news, 1):
            print(f"   {i}. {news.get('title')}")
        
        # 5. è·å–æ–°é—»æ‘˜è¦
        print("\n5. 24å°æ—¶æ–°é—»æ‘˜è¦:")
        summary = await collector.get_news_summary(hours=24)
        print(f"   æ€»æ–°é—»æ•°: {summary['total_news']}")
        print(f"   å¿«è®¯æ•°: {summary['flash_count']}")
        print(f"   æ–‡ç« æ•°: {summary['article_count']}")
        print(f"   çƒ­é—¨å…³é”®è¯: {', '.join(summary['top_keywords'])}")
        
        # 6. è½¬æ¢ä¸ºDataFrame
        print("\n6. è½¬æ¢ä¸ºDataFrame:")
        df = collector.news_to_dataframe(important_news)
        if not df.empty:
            print(f"   DataFrameå½¢çŠ¶: {df.shape}")
            print(f"   åˆ—å: {list(df.columns)}")
            print(f"   å‰3æ¡æ–°é—»æ ‡é¢˜:")
            for title in df['title'].head(3):
                print(f"     - {title}")

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(news_collector_demo())